{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNU5XLU4AAVrLZyTQ4dmYjW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TapasKumarDutta1/Multihead_attention/blob/master/Untitled60.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZFyjobplBto",
        "outputId": "ab7cd2d7-e8f8-4d68-d1b2-b25b496b23fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 224, 224, 16  448         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 224, 224, 16  64         ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                   (None, 224, 224, 16  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 112, 112, 16  0           ['re_lu[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 112, 112, 16  2320        ['max_pooling2d[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 112, 112, 16  64         ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)                 (None, 112, 112, 16  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 16)  0           ['re_lu_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 56, 56, 32)   4640        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 56, 56, 32)  128         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)                 (None, 56, 56, 32)   0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 56, 56, 32)   9248        ['re_lu_2[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 56, 56, 32)  128         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_3 (ReLU)                 (None, 56, 56, 32)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 56, 56, 32)   9248        ['re_lu_3[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 56, 56, 32)  128         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_4 (ReLU)                 (None, 56, 56, 32)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 56, 56, 32)   9248        ['re_lu_4[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 56, 56, 32)  128         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_5 (ReLU)                 (None, 56, 56, 32)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 56, 56, 128)  0           ['re_lu_2[0][0]',                \n",
            "                                                                  're_lu_3[0][0]',                \n",
            "                                                                  're_lu_4[0][0]',                \n",
            "                                                                  're_lu_5[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 56, 56, 64)   8256        ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 56, 56, 64)   1088        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 56, 56, 64)  256         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 56, 56, 64)  256         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_6 (ReLU)                 (None, 56, 56, 64)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " re_lu_7 (ReLU)                 (None, 56, 56, 64)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 56, 56, 64)   0           ['re_lu_6[0][0]',                \n",
            "                                                                  're_lu_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 56, 56, 64)   4160        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 56, 56, 64)  256         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_8 (ReLU)                 (None, 56, 56, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 64)  0           ['re_lu_8[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 28, 28, 64)   36928       ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 28, 28, 64)  256         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_9 (ReLU)                 (None, 28, 28, 64)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 28, 28, 64)   36928       ['re_lu_9[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 28, 28, 64)  256         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_10 (ReLU)                (None, 28, 28, 64)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 28, 28, 64)   36928       ['re_lu_10[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 28, 28, 64)  256         ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_11 (ReLU)                (None, 28, 28, 64)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 28, 28, 64)   36928       ['re_lu_11[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 28, 28, 64)  256         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_12 (ReLU)                (None, 28, 28, 64)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 28, 28, 256)  0           ['re_lu_9[0][0]',                \n",
            "                                                                  're_lu_10[0][0]',               \n",
            "                                                                  're_lu_11[0][0]',               \n",
            "                                                                  're_lu_12[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 28, 28, 128)  32896       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 28, 28, 128)  8320        ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 28, 28, 128)  512        ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 28, 28, 128)  512        ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_13 (ReLU)                (None, 28, 28, 128)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_14 (ReLU)                (None, 28, 28, 128)  0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 28, 28, 128)  0           ['re_lu_13[0][0]',               \n",
            "                                                                  're_lu_14[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 28, 28, 128)  16512       ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 28, 28, 128)  512        ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_15 (ReLU)                (None, 28, 28, 128)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 128)  0          ['re_lu_15[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 14, 14, 128)  147584      ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 14, 14, 128)  512        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_16 (ReLU)                (None, 14, 14, 128)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 14, 14, 128)  147584      ['re_lu_16[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 14, 14, 128)  512        ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_17 (ReLU)                (None, 14, 14, 128)  0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 14, 14, 128)  147584      ['re_lu_17[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 14, 14, 128)  512        ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_18 (ReLU)                (None, 14, 14, 128)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 14, 14, 128)  147584      ['re_lu_18[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 14, 14, 128)  512        ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_19 (ReLU)                (None, 14, 14, 128)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 14, 14, 512)  0           ['re_lu_16[0][0]',               \n",
            "                                                                  're_lu_17[0][0]',               \n",
            "                                                                  're_lu_18[0][0]',               \n",
            "                                                                  're_lu_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 14, 14, 256)  131328      ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 14, 14, 256)  33024       ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_20 (ReLU)                (None, 14, 14, 256)  0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_21 (ReLU)                (None, 14, 14, 256)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 14, 14, 256)  0           ['re_lu_20[0][0]',               \n",
            "                                                                  're_lu_21[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 14, 14, 256)  65792       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_22 (ReLU)                (None, 14, 14, 256)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 14, 14, 32)   8224        ['re_lu_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 14, 14, 32)   8224        ['re_lu_22[0][0]']               \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 14, 14, 32)   0           ['conv2d_24[0][0]']              \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 14, 14, 32)   0           ['conv2d_23[0][0]']              \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 196, 32)      0           ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 196, 32)      0           ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose (TFOpLa  (None, 32, 196)     0           ['reshape_1[0][0]']              \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 14, 14, 32)   8224        ['re_lu_22[0][0]']               \n",
            "                                                                                                  \n",
            " tf.linalg.matmul (TFOpLambda)  (None, 196, 196)     0           ['reshape[0][0]',                \n",
            "                                                                  'tf.compat.v1.transpose[0][0]'] \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 14, 14, 32)   0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 14, 14, 1)    0           ['re_lu_22[0][0]']               \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 14, 14, 1)    0           ['re_lu_22[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 196, 196)     0           ['tf.linalg.matmul[0][0]']       \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)            (None, 196, 32)      0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 14, 14, 2)    0           ['lambda[0][0]',                 \n",
            "                                                                  'lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " tf.linalg.matmul_1 (TFOpLambda  (None, 196, 32)     0           ['activation_3[0][0]',           \n",
            " )                                                                'reshape_2[0][0]']              \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 14, 14, 2)    0           ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " reshape_3 (Reshape)            (None, 14, 14, 32)   0           ['tf.linalg.matmul_1[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 14, 14, 1)    3           ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 14, 14, 256)  8448        ['reshape_3[0][0]']              \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 14, 14, 1)    0           ['conv2d_27[0][0]']              \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 14, 14, 256)  0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 14, 14, 256)  0           ['activation_6[0][0]',           \n",
            "                                                                  're_lu_22[0][0]']               \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 14, 14, 256)  0           ['activation_4[0][0]',           \n",
            "                                                                  'multiply[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 14, 14, 256)  65792       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 256)   0           ['conv2d_28[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 32)     8192        ['max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 32)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 256)    8192        ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 256)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 14, 14, 256)  0           ['activation_8[0][0]',           \n",
            "                                                                  'conv2d_28[0][0]']              \n",
            "                                                                                                  \n",
            " global_max_pooling2d (GlobalMa  (None, 256)         0           ['multiply_1[0][0]']             \n",
            " xPooling2D)                                                                                      \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 256)          0           ['global_max_pooling2d[0][0]']   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 3)            771         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,199,734\n",
            "Trainable params: 1,195,190\n",
            "Non-trainable params: 4,544\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Attention\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.activations import *\n",
        "from tensorflow.keras.initializers import *\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "def block(inputs,f):\n",
        "    a=Conv2D(f,3,padding='same')(inputs)\n",
        "    a=BatchNormalization()(a)\n",
        "    a=ReLU()(a)\n",
        "    b=Conv2D(f,3,padding='same')(a)\n",
        "    b=BatchNormalization()(b)\n",
        "    b=ReLU()(b)\n",
        "    c=Conv2D(f,3,padding='same')(b)\n",
        "    c=BatchNormalization()(c)\n",
        "    c=ReLU()(c)\n",
        "    d=Conv2D(f,3,padding='same')(c)\n",
        "    d=BatchNormalization()(d)\n",
        "    d=ReLU()(d)\n",
        "    mid=Concatenate()([a,b,c,d])\n",
        "    \n",
        "    mid=Conv2D(2*f,1,padding='same')(mid)\n",
        "    mid=BatchNormalization()(mid)\n",
        "    mid=ReLU()(mid)\n",
        "    \n",
        "    x=Conv2D(f*2,1, padding='same')(inputs)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=ReLU()(x)\n",
        "    \n",
        "    x=Add()([mid,x])\n",
        "    \n",
        "    y=Conv2D(f*2,1, padding='same')(x)\n",
        "    y=BatchNormalization()(y)\n",
        "    y=ReLU()(y)\n",
        "    return y\n",
        "\n",
        "\n",
        "\n",
        "def Global_attention_block(C_A):\n",
        "    \n",
        "    x=Lambda(lambda x: K.mean(x,axis=-1,keepdims=True))  (C_A)\n",
        "    y=Lambda(lambda x: K.max(x,axis=-1,keepdims=True))  (C_A)\n",
        "    \n",
        "    x=Concatenate()([x,y])\n",
        "    x=Activation('relu') (x)\n",
        "    x=Conv2D(1,1, padding='same') (x)\n",
        "    x=Activation('sigmoid') (x)\n",
        "    S_A=Multiply()([x,C_A])\n",
        "    return S_A\n",
        "\n",
        "def self_attention(inp):\n",
        "    shp=inp.shape\n",
        "    a=Conv2D(shp[3]//8,1, padding='same') (inp)\n",
        "    a=Activation('relu') (a)\n",
        "    b=Conv2D(shp[3]//8,1, padding='same') (inp)\n",
        "    b=Activation('relu') (b)\n",
        "    c=Conv2D(shp[3]//8,1, padding='same') (inp)\n",
        "    c=Activation('relu') (c)\n",
        "    \n",
        "    a=Reshape(( shp[1]*shp[2], shp[3]//8))(a)\n",
        "    b=Reshape(( shp[1]*shp[2], shp[3]//8))(b)\n",
        "    b=K.permute_dimensions(b, (0, 2, 1))\n",
        "    c=Reshape(( shp[1]*shp[2], shp[3]//8))(c)\n",
        "    inter=K.batch_dot(a,b)\n",
        "    inter=Activation('softmax') (inter)\n",
        "    out=K.batch_dot(inter,c)\n",
        "    out=Reshape(( shp[1],shp[2], shp[3]//8))(out)\n",
        "    out=Conv2D(shp[3],1, padding='same') (out)\n",
        "    out=Activation('relu') (out)\n",
        "    return out\n",
        "\n",
        "def channel_attention(inputs):\n",
        "    shape=K.int_shape(inputs)\n",
        "    x=MaxPooling2D(pool_size=(shape[1],shape[2])) (inputs)\n",
        "    x=Conv2D(shape[3]//8,1, padding='same',kernel_initializer='he_normal', use_bias=False) (x)\n",
        "    x=Activation('relu') (x)\n",
        "    x=Conv2D(shape[3],1, padding='same',kernel_initializer='he_normal', use_bias=False) (x)\n",
        "    x=Activation('sigmoid') (x)\n",
        "    x=Multiply()([x,inputs])\n",
        "    return x\n",
        "\n",
        "\n",
        "def load_model():   \n",
        "  K.clear_session() \n",
        "  inputs = Input(shape=(224,224,3))\n",
        "  x=Conv2D(16,3,padding='same')(inputs)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=ReLU()(x)\n",
        "  x=MaxPooling2D()(x)\n",
        "  \n",
        "  x=Conv2D(16,3,padding='same')(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=ReLU()(x)\n",
        "  x=MaxPooling2D()(x)\n",
        "    \n",
        "  a1=block(x,32)\n",
        "  x=MaxPooling2D()(a1)\n",
        "\n",
        "  a2=block(x,64)\n",
        "  x=MaxPooling2D()(a2)\n",
        "    \n",
        "  a3=block(x,128)\n",
        "\n",
        "  a31=self_attention(a3)\n",
        "  a32=Global_attention_block(a3)\n",
        "  a3=Add()([a31,a32])\n",
        "  a3=Conv2D(256,1,padding='same')(a3)\n",
        "  x=channel_attention(a3)\n",
        "    \n",
        "  x=GlobalMaxPooling2D()(x)\n",
        "    \n",
        "  x=Dropout(0.5)(x)\n",
        "  x=Dense(3,activation='softmax')(x)\n",
        "  model = Model(inputs=inputs, outputs=x)\n",
        "  \n",
        "  return model\n",
        "load_model().summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#None\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.activations import *\n",
        "from tensorflow.keras.initializers import *\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "def block(inputs,f):\n",
        "    a=Conv2D(f,3,padding='same')(inputs)\n",
        "    a=BatchNormalization()(a)\n",
        "    a=ReLU()(a)\n",
        "    b=Conv2D(f,3,padding='same')(a)\n",
        "    b=BatchNormalization()(b)\n",
        "    b=ReLU()(b)\n",
        "    c=Conv2D(f,3,padding='same')(b)\n",
        "    c=BatchNormalization()(c)\n",
        "    c=ReLU()(c)\n",
        "    d=Conv2D(f,3,padding='same')(c)\n",
        "    d=BatchNormalization()(d)\n",
        "    d=ReLU()(d)\n",
        "    mid=Concatenate()([a,b,c,d])\n",
        "    \n",
        "    mid=Conv2D(2*f,1,padding='same')(mid)\n",
        "    mid=BatchNormalization()(mid)\n",
        "    mid=ReLU()(mid)\n",
        "    \n",
        "    x=Conv2D(f*2,1)(inputs)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=ReLU()(x)\n",
        "    \n",
        "    x=Add()([mid,x])\n",
        "    \n",
        "    y=Conv2D(f*2,1)(x)\n",
        "    y=BatchNormalization()(y)\n",
        "    y=ReLU()(y)\n",
        "    return y\n",
        "\n",
        "\n",
        "\n",
        "def Global_attention_block(C_A):\n",
        "    \n",
        "    x=Lambda(lambda x: K.mean(x,axis=-1,keepdims=True))  (C_A)\n",
        "    y=Lambda(lambda x: K.max(x,axis=-1,keepdims=True))  (C_A)\n",
        "    \n",
        "    x=Concatenate()([x,y])\n",
        "    x=Activation('relu') (x)\n",
        "    x=Conv2D(1,1, padding='same') (x)\n",
        "    x=Activation('sigmoid') (x)\n",
        "    S_A=Multiply()([x,C_A])\n",
        "    return S_A\n",
        "\n",
        "def self_attention(inp):\n",
        "    shp=inp.shape\n",
        "    a=Conv2D(shp[3]//8,1, padding='same') (inp)\n",
        "    a=Activation('relu') (a)\n",
        "    b=Conv2D(shp[3]//8,1, padding='same') (inp)\n",
        "    b=Activation('relu') (b)\n",
        "    c=Conv2D(shp[3]//8,1, padding='same') (inp)\n",
        "    c=Activation('relu') (c)\n",
        "    \n",
        "    a=Reshape(( shp[1]*shp[2], shp[3]//8))(a)\n",
        "    b=Reshape(( shp[1]*shp[2], shp[3]//8))(b)\n",
        "    b=K.permute_dimensions(b, (0, 2, 1))\n",
        "    c=Reshape(( shp[1]*shp[2], shp[3]//8))(c)\n",
        "    inter=K.batch_dot(a,b)\n",
        "    inter=Activation('softmax') (inter)\n",
        "    out=K.batch_dot(inter,c)\n",
        "    out=Reshape(( shp[1],shp[2], shp[3]//8))(out)\n",
        "    out=Conv2D(shp[3],1, padding='same') (out)\n",
        "    out=Activation('relu') (out)\n",
        "    return out\n",
        "\n",
        "def channel_attention(inputs):\n",
        "    shape=K.int_shape(inputs)\n",
        "    x=MaxPooling2D(pool_size=(shape[1],shape[2])) (inputs)\n",
        "    x=Conv2D(shape[3]//8,1, padding='same',kernel_initializer='he_normal', use_bias=False) (x)\n",
        "    x=Activation('relu') (x)\n",
        "    x=Conv2D(shape[3],1, padding='same',kernel_initializer='he_normal', use_bias=False) (x)\n",
        "    x=Activation('sigmoid') (x)\n",
        "    x=Multiply()([x,inputs])\n",
        "    return x\n",
        "\n",
        "def load_model():   \n",
        "  K.clear_session() \n",
        "  inputs = Input(shape=(224,224,3))\n",
        "  x=Conv2D(16,3,padding='same')(inputs)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=ReLU()(x)\n",
        "  x=MaxPooling2D()(x)\n",
        "  \n",
        "  x=Conv2D(16,3,padding='same')(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=ReLU()(x)\n",
        "  x=MaxPooling2D()(x)\n",
        "    \n",
        "  a1=block(x,32)\n",
        "  x=MaxPooling2D()(a1)\n",
        "\n",
        "  a2=block(x,64)\n",
        "  x=MaxPooling2D()(a2)\n",
        "    \n",
        "  a3=block(x,128)\n",
        "\n",
        "#   a31=self_attention(a3)\n",
        "#   a32=Global_attention_block(a3)\n",
        "#   a3=Add()([a31,a32])\n",
        "#   a3=Conv2D(256,1,padding='same')(a3)\n",
        "#   x=channel_attention(a3)\n",
        "    \n",
        "  x=GlobalMaxPooling2D()(a3)\n",
        "    \n",
        "  x=Dropout(0.5)(x)\n",
        "  x=Dense(3,activation='softmax')(x)\n",
        "  model = Model(inputs=inputs, outputs=x)\n",
        "  \n",
        "  return model\n",
        "load_model().summary()"
      ],
      "metadata": {
        "id": "hZJ5xbB6lICi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60c06ae1-f214-450a-863b-80ce5719e834"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 224, 224, 16  448         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 224, 224, 16  64         ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                   (None, 224, 224, 16  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 112, 112, 16  0           ['re_lu[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 112, 112, 16  2320        ['max_pooling2d[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 112, 112, 16  64         ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)                 (None, 112, 112, 16  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 16)  0           ['re_lu_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 56, 56, 32)   4640        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 56, 56, 32)  128         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)                 (None, 56, 56, 32)   0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 56, 56, 32)   9248        ['re_lu_2[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 56, 56, 32)  128         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_3 (ReLU)                 (None, 56, 56, 32)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 56, 56, 32)   9248        ['re_lu_3[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 56, 56, 32)  128         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_4 (ReLU)                 (None, 56, 56, 32)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 56, 56, 32)   9248        ['re_lu_4[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 56, 56, 32)  128         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_5 (ReLU)                 (None, 56, 56, 32)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 56, 56, 128)  0           ['re_lu_2[0][0]',                \n",
            "                                                                  're_lu_3[0][0]',                \n",
            "                                                                  're_lu_4[0][0]',                \n",
            "                                                                  're_lu_5[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 56, 56, 64)   8256        ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 56, 56, 64)   1088        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 56, 56, 64)  256         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 56, 56, 64)  256         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_6 (ReLU)                 (None, 56, 56, 64)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " re_lu_7 (ReLU)                 (None, 56, 56, 64)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 56, 56, 64)   0           ['re_lu_6[0][0]',                \n",
            "                                                                  're_lu_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 56, 56, 64)   4160        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 56, 56, 64)  256         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_8 (ReLU)                 (None, 56, 56, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 64)  0           ['re_lu_8[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 28, 28, 64)   36928       ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 28, 28, 64)  256         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_9 (ReLU)                 (None, 28, 28, 64)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 28, 28, 64)   36928       ['re_lu_9[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 28, 28, 64)  256         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_10 (ReLU)                (None, 28, 28, 64)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 28, 28, 64)   36928       ['re_lu_10[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 28, 28, 64)  256         ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_11 (ReLU)                (None, 28, 28, 64)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 28, 28, 64)   36928       ['re_lu_11[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 28, 28, 64)  256         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_12 (ReLU)                (None, 28, 28, 64)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 28, 28, 256)  0           ['re_lu_9[0][0]',                \n",
            "                                                                  're_lu_10[0][0]',               \n",
            "                                                                  're_lu_11[0][0]',               \n",
            "                                                                  're_lu_12[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 28, 28, 128)  32896       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 28, 28, 128)  8320        ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 28, 28, 128)  512        ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 28, 28, 128)  512        ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_13 (ReLU)                (None, 28, 28, 128)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_14 (ReLU)                (None, 28, 28, 128)  0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 28, 28, 128)  0           ['re_lu_13[0][0]',               \n",
            "                                                                  're_lu_14[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 28, 28, 128)  16512       ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 28, 28, 128)  512        ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_15 (ReLU)                (None, 28, 28, 128)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 128)  0          ['re_lu_15[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 14, 14, 128)  147584      ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 14, 14, 128)  512        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_16 (ReLU)                (None, 14, 14, 128)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 14, 14, 128)  147584      ['re_lu_16[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 14, 14, 128)  512        ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_17 (ReLU)                (None, 14, 14, 128)  0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 14, 14, 128)  147584      ['re_lu_17[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 14, 14, 128)  512        ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_18 (ReLU)                (None, 14, 14, 128)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 14, 14, 128)  147584      ['re_lu_18[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 14, 14, 128)  512        ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_19 (ReLU)                (None, 14, 14, 128)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 14, 14, 512)  0           ['re_lu_16[0][0]',               \n",
            "                                                                  're_lu_17[0][0]',               \n",
            "                                                                  're_lu_18[0][0]',               \n",
            "                                                                  're_lu_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 14, 14, 256)  131328      ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 14, 14, 256)  33024       ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_20 (ReLU)                (None, 14, 14, 256)  0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_21 (ReLU)                (None, 14, 14, 256)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 14, 14, 256)  0           ['re_lu_20[0][0]',               \n",
            "                                                                  're_lu_21[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 14, 14, 256)  65792       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_22 (ReLU)                (None, 14, 14, 256)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " global_max_pooling2d (GlobalMa  (None, 256)         0           ['re_lu_22[0][0]']               \n",
            " xPooling2D)                                                                                      \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 256)          0           ['global_max_pooling2d[0][0]']   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 3)            771         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,084,435\n",
            "Trainable params: 1,079,891\n",
            "Non-trainable params: 4,544\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XU8L6_jaVznw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}