{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fold_3_final.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/data/blob/master/fold_3_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-QYgRhGfGLZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ec3871b9-ba07-4b59-da52-d731a9e8d0d6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPJzX5fywOe6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "0a74af4f-9ab1-436b-f9e0-8c4dea746413"
      },
      "source": [
        "\n",
        "from keras.optimizers import *\n",
        "import cv2\n",
        "from keras.utils import to_categorical\n",
        "from matplotlib import pyplot as plt\n",
        "import glob, os\n",
        "from matplotlib import pyplot as plt\n",
        "import h5py\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import gc\n",
        "from keras.applications import *\n",
        "from keras.layers import *\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "import keras\n",
        "import pandas as pd\n",
        "from keras.applications.nasnet import NASNetMobile, preprocess_input\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "import h5py\n",
        "from keras.optimizers import Adam\n",
        "import cv2\n",
        "from keras.utils import to_categorical\n",
        "from matplotlib import pyplot as plt\n",
        "import glob, os\n",
        "from matplotlib import pyplot as plt\n",
        "import h5py\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import gc\n",
        "from keras.applications import *\n",
        "from keras.layers import *\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC8imWIHxEHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = F\"/content/gdrive/My Drive/check.npy\" \n",
        "df=np.load(path,allow_pickle=True)\n",
        "df=df.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7IAfQuywQmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#shuffle samples\n",
        "def unison_shuffled_copies(a, b):\n",
        "    assert len(a) == len(b)\n",
        "    p = np.random.permutation(len(a))\n",
        "    return a[p], b[p]\n",
        "\n",
        "\n",
        "\n",
        "#change targets\n",
        "def change(img):\n",
        "    resized = cv2.resize(img, (299,299), interpolation = cv2.INTER_AREA )\n",
        "    return resized\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#get train and test splits\n",
        "def get_trn_tst(df,tst_fold):\n",
        "  dimension=224\n",
        "  idx=np.asarray(df['fold'])\n",
        "  y=np.asarray(df['label'])\n",
        "  y-=1\n",
        "  img=np.asarray(df['image'])\n",
        "  img1=[]\n",
        "  img1=np.asarray(img)\n",
        "  del([img])\n",
        "  gc.collect()\n",
        "  trn_y=np.asarray(y[(idx!=tst_fold)])\n",
        "  trn_img=np.asarray(img1[(idx!=tst_fold)])\n",
        "  tst_y=np.asarray(y[(idx==tst_fold)])\n",
        "  tst_img=img1[idx==tst_fold]\n",
        "  trn_img=np.repeat(trn_img.reshape((trn_img.shape[0],dimension,dimension,1)),1,axis=3)\n",
        "  tst_img=np.repeat(tst_img.reshape((tst_img.shape[0],dimension,dimension,1)),1,axis=3)\n",
        "  return (trn_img.copy(),trn_y.copy()),(tst_img.copy(),tst_y.copy())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNW0pskZwcEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model(last=True):   \n",
        "  inp=Input((224,224,1,))\n",
        "  x=Convolution2D(8,(7,7),activation='relu')(inp)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=MaxPooling2D(2,2)(x)\n",
        "  x=Convolution2D(32,(5,5),activation='relu')(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=MaxPooling2D(2,2)(x)\n",
        "  x=Convolution2D(64,(5,5),activation='relu')(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=MaxPooling2D(2,2)(x)\n",
        "  x=Convolution2D(128,(5,5),activation='relu')(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=MaxPooling2D(2,2)(x)\n",
        "  x=Convolution2D(256,(5,5),activation='relu')(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=MaxPooling2D(2,2)(x)\n",
        "  x=GlobalAveragePooling2D()(x)\n",
        "  x=Reshape((1,1,256))(x)\n",
        "  x=Flatten()(x)\n",
        "  x=Dense(512,activation='sigmoid')(x)\n",
        "  x=Dropout(0.5)(x)\n",
        "  x=Dense(3,activation='softmax')(x)\n",
        "  model=Model(inputs=inp,outputs=x)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIQSvrhBwdnu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "outputId": "9d80c155-9ff6-49bf-a977-a860bef088f6"
      },
      "source": [
        "mod=load_model()\n",
        "mod.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 1)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 218, 218, 8)       400       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 218, 218, 8)       32        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 109, 109, 8)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 105, 105, 32)      6432      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 105, 105, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 52, 52, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 48, 48, 64)        51264     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 48, 48, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 20, 20, 128)       204928    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 20, 20, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 10, 10, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 6, 6, 256)         819456    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 6, 6, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 1539      \n",
            "=================================================================\n",
            "Total params: 1,217,555\n",
            "Trainable params: 1,216,579\n",
            "Non-trainable params: 976\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWXwzoslwfCL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import pandas as pd\n",
        "from keras.applications.nasnet import NASNetMobile, preprocess_input\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "def rotate_image(image, angle):\n",
        "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "  return result\n",
        "def Hflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Fliplr(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def Vflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Flipud(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def noise(images):\n",
        "    ls=[]\n",
        "    for i in images:\n",
        "        x = np.random.normal(loc=0, scale=0.05, size=(dimension,dimension,3))\n",
        "        ls.append(i+x)\n",
        "    return ls\n",
        "def rotate(images):\n",
        "    ls=[]\n",
        "    for angle in range(-15,20,5):\n",
        "        for image in images:\n",
        "            ls.append(rotate_image(image,angle).reshape((224,224,1)))\n",
        "    return ls\n",
        "\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "  def __init__(self, images, labels, batch_size=64, image_dimensions = (96 ,96 ,3), shuffle=False, augment=False):\n",
        "    self.labels       = labels              # array of labels\n",
        "    self.images = images        # array of image paths\n",
        "    self.batch_size   = batch_size          # batch size\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.floor(self.labels.shape[0] / self.batch_size))\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    self.indexes = np.arange(self.labels.shape[0])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\t\t# selects indices of data for next batch\n",
        "    indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "    # select data and load images\n",
        "    labels = self.labels.loc[indexes]\n",
        "    img = [self.images[k].astype(np.float32) for k in indexes]\n",
        "    imgH=Hflip(img)\n",
        "    imgV=Vflip(img)\n",
        "    imgR=rotate(img)\n",
        "    images=[]\n",
        "    images.extend(imgH)\n",
        "    images.extend(imgV)\n",
        "    images.extend(imgR)\n",
        "    lbl=labels.copy()\n",
        "    labels=pd.DataFrame()\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    img=np.asarray(images)\n",
        "    #images = np.array([preprocess_input(img) for img in images])\n",
        "    return img, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC-Dm3ulwgVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "best_accuracy_last={}\n",
        "final_accuracy_last={}\n",
        "history_last={}\n",
        "answers_last={}\n",
        "predictions_last={}\n",
        "predictions_last_best={}\n",
        "times_last={}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvsVb2H2whrN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1be04ede-9775-47c2-b4d3-1ff54c2923c2"
      },
      "source": [
        "  def upd(dk,data):\n",
        "    if dk==0:\n",
        "        dk=data\n",
        "    else:\n",
        "        for ky in data.keys():\n",
        "            dk[ky].extend(data[ky])\n",
        "    return dk\n",
        "  index=3\n",
        "  epoch=75\n",
        "  pre_acc=0\n",
        "  best=0\n",
        "  fold='fold_'+str(index)\n",
        "  trn,tst=get_trn_tst(df,index)\n",
        "  history_last[fold]=0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  trn_x,trn_y=unison_shuffled_copies(trn[0],trn[1])\n",
        "  tst_x,tst_y=unison_shuffled_copies(tst[0],tst[1])\n",
        "\n",
        "\n",
        "\n",
        "  model=load_model(last=False)\n",
        "\n",
        "\n",
        "  \n",
        "  #compiling the model\n",
        "  model.compile(optimizer=Adam(1e-3,decay=1e-4), \n",
        "                     loss='categorical_crossentropy', \n",
        "                     metrics=['accuracy'])\n",
        "  train_data = DataGenerator(trn_x,pd.get_dummies(trn_y), batch_size=4, augment=True)\n",
        "  ln=len(trn_y)\n",
        "  del([trn_x,trn_y,trn,tst])\n",
        "  gc.collect()\n",
        "  #fitting the model\n",
        "  #timing\n",
        "  start=time.time()\n",
        "  for i in range(epoch):\n",
        "      hist=model.fit_generator(train_data,epochs=1,steps_per_epoch=ln//4)\n",
        "      history_last[fold]=upd(history_last[fold],hist.history)\n",
        "\n",
        "  end=time.time()\n",
        "  times_last[fold]=end-start\n",
        "\n",
        "  #getting the prediction \n",
        "  pre=model.predict(tst_x)\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "  #select the maximum position\n",
        "  pre=np.argmax(pre,1)\n",
        "  predictions_last[fold]=pre\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "  #getting the accuracy\n",
        "  new_acc=accuracy_score(pre,tst_y)\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  #storing the predictions\n",
        "  final_accuracy_last[fold]=new_acc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #storing the answers\n",
        "  answers_last[fold]=tst_y\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "  #freeing memory\n",
        "  del([tst_x,tst_y])\n",
        "  gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "623/623 [==============================] - 55s 88ms/step - loss: 0.8441 - accuracy: 0.6402\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 83ms/step - loss: 0.5514 - accuracy: 0.7596\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 83ms/step - loss: 0.4176 - accuracy: 0.8259\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 0.3147 - accuracy: 0.8734\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 0.2388 - accuracy: 0.9043\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 83ms/step - loss: 0.1741 - accuracy: 0.9328\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 0.1269 - accuracy: 0.9511\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 0.0912 - accuracy: 0.9650\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 0.0489 - accuracy: 0.9822\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 0.0513 - accuracy: 0.9811\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 0.0269 - accuracy: 0.9907\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 0.0093 - accuracy: 0.9975\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 0.0023 - accuracy: 0.9997\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 7.0140e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 3.8113e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 3.4373e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 1.9519e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 1.0556e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 7.6367e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 6.8155e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 5.4448e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 0.1191 - accuracy: 0.9701\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 0.0101 - accuracy: 0.9969\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 0.0021 - accuracy: 0.9999\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 8.0264e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 4.8088e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 3.0883e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 1.9629e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 1.3970e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 9.5590e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 7.1875e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 4.8622e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 5.4295e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 3.1358e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 3.8948e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 0.0567 - accuracy: 0.9857\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 0.0027 - accuracy: 0.9995\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 6.0413e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 3.4289e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 2.2051e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 1.7908e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 1.1238e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 8.1979e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 5.2997e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 4.3824e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 3.1592e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 2.7053e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 2.1495e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 1.4334e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 1.0561e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 7.9536e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 7.0969e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 4.9770e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 3.7341e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 3.4481e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 3.7910e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 0.0144 - accuracy: 0.9956\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 0.0017 - accuracy: 0.9994\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 2.2406e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 1.0749e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 6.0696e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 3.8676e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 3.4208e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 2.3321e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 2.0300e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 1.5916e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 1.0980e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 8.1367e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 7.7552e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 5.7994e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 6.1219e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 4.1473e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 2.7935e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 84ms/step - loss: 2.0230e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 52s 83ms/step - loss: 2.8234e-06 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFQlBar9Kp7y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "e1a0ffe9-42b8-421a-f5d2-69e37e662016"
      },
      "source": [
        "plt.plot(history_last[fold]['loss'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe495a7a860>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbuElEQVR4nO3deZCc9X3n8fe3u+fUzEiaQyOhkTRCGgQyaw4JgTkczqygHKhdiANFHGcLh3WVWZOKN7uwSSiv94/4WjZOFbGDnaxTJIYFfETlCAvMFZsYzIjDIAmh0YUkkDSje2Y0Z3/3j3561NMaaVpSj55+nv68iin6efqp6c90S5959Ht+z/OYuyMiItGXCDuAiIgUhwpdRCQmVOgiIjGhQhcRiQkVuohITKTCeuHm5mZvb28P6+VFRCJp7dq1Pe7eMtFzoRV6e3s7nZ2dYb28iEgkmdn2Ez2nIRcRkZhQoYuIxIQKXUQkJlToIiIxoUIXEYkJFbqISEyo0EVEYiJyhf76tv18/WfvkU7rsr8iIrkiV+hv7zjI37y0md6hkbCjiIiUlMgVen115uTWIwMqdBGRXJEr9IbqCgAOHx0OOYmISGmJXKHXB4WuPXQRkfEiWOjZIRftoYuI5IpcoTfUBEMuKnQRkXEiV+g6KCoiMrGCCt3MVprZRjPrMrMHJnh+vpm9aGZvmtlvzOyW4kfNyBa6DoqKiIw3aaGbWRJ4BLgZWArcZWZL8zb7c+BJd78EuBP4m2IHzapKJalKJbSHLiKSp5A99BVAl7tvcfch4AngtrxtHGgIHk8HPixexOPVV1dwWIUuIjJOIbegmwvsyFneCVyet82XgWfN7L8A04Abi5LuBBpqUjooKiKSp1gHRe8Cvu/ubcAtwGNmdtz3NrN7zazTzDq7u7tP+8Xqqys05CIikqeQQt8FzMtZbgvW5boHeBLA3X8FVAPN+d/I3R919+XuvrylZcKbVhekoTqleegiInkKKfTXgQ4zW2hmlWQOeq7K2+YD4AYAM7uATKGf/i74JBqqKzTLRUQkz6SF7u4jwH3AGmADmdks68zsK2Z2a7DZl4A/MrO3gceBP3T3Kbu+bX11SkMuIiJ5CjkoiruvBlbnrXso5/F64KriRjsxFbqIyPEid6YoZIZcjg6PMjyaDjuKiEjJiGSh6/R/EZHjRbLQxy7QpQOjIiJjIlnouia6iMjxIlrouia6iEi+SBb62G3oVOgiImMiWehjl9DVkIuIyJhIFnqDxtBFRI4TyUKv000uRESOE8lCTyaMuiqdLSoikiuShQ7Z0/+1hy4ikhXZQm+ortAsFxGRHJEtdF2gS0RkvMgWekON9tBFRHJFttC1hy4iMp4KXUQkJiJb6Nnb0E3hjZFERCIlsoVeX13BSNoZGNZNLkREINKFrisuiojkimyhj93kQoUuIgJEuNB1xUURkfEiW+i64qKIyHgRLnRdcVFEJFdkC133FRURGS+yhd5Qkx1D1x66iAhEuNBrKpIkE6ZpiyIigcgWupnp9H8RkRyRLXQ4dvq/iIhEvNC1hy4icowKXUQkJiJd6LoNnYjIMZEu9PrqCu2hi4gEIl3oDTUp7aGLiAQiXej11RX0Do6QTusmFyIikS70huoU7tA7pGEXEZGIF3pwTXTNRRcRiXahH7trkfbQRUQiXui64qKISFZBhW5mK81so5l1mdkDJ9jm02a23szWmdkPihtzYmNXXNSQi4gIqck2MLMk8AhwE7ATeN3MVrn7+pxtOoAHgavc/YCZzZqqwLnG9tAHVegiIoXsoa8Autx9i7sPAU8At+Vt80fAI+5+AMDd9xY35sQ0hi4ickwhhT4X2JGzvDNYl+s84Dwze8XMXjWzlRN9IzO718w6zayzu7v79BLnqNdt6ERExhTroGgK6ACuBe4CvmtmM/I3cvdH3X25uy9vaWk54xetSiWpSiW0hy4iQmGFvguYl7PcFqzLtRNY5e7D7r4VeJ9MwU+5hpoKDqvQRUQKKvTXgQ4zW2hmlcCdwKq8bX5CZu8cM2smMwSzpYg5T6i+WtdzERGBAgrd3UeA+4A1wAbgSXdfZ2ZfMbNbg83WAPvMbD3wIvCn7r5vqkLn0hUXRUQyJp22CODuq4HVeeseynnswJ8EX2dVQ3VKB0VFRIj4maKQuZ7LEQ25iIhEv9B1GzoRkYzIF3pmlov20EVEIl/o9VUpBobTDI+mw44iIhKqyBd6Q42uuCgiAjEo9Ozp/4c000VEylzkC312QzUAHx06GnISEZFwRb7Q5zXWArBjf3/ISUREwhX5Qp8zvZpkwvhAhS4iZS7yhZ5KJpg7o4Yd+zXkIiLlLfKFDjC/sVZ76CJS9mJR6PMaazSGLiJlLyaFXsu+viH6BjUXXUTKVzwKfWYw0+WA9tJFpHzFotDnj01d1IFRESlfsSp0HRgVkXIWi0KfUVtBXVVKB0ZFpKzFotDNjHmNtSp0ESlrsSh0gHkzazTkIiJlLTaFPr+xlh0H+snc3lREpPzEptDnNdYyMJymu3cw7CgiIqGITaHP11UXRaTMxabQ52kuuoiUudgUetvMGkBz0UWkfMWm0KsrkrQ2VGnIRUTKVmwKHTLXdNEeuoiUq1gV+nydXCQiZSxWhd7WWMtHhwcYGkmHHUVE5KyLVaHPb6zFHXYd1EwXESk/sSt00Fx0ESlPsSr0eY2auigi5StWhd5aX01lMqE9dBEpS7Eq9ETCaJtZo1vRiUhZilWhQ+YSABpyEZFyFMNCr9H1XESkLMWu0Oc31nLo6DCH+ofDjiIiclbFstABjaOLSNmJXaEvaJoGwObu3pCTiIicXQUVupmtNLONZtZlZg+cZLvbzczNbHnxIp6ac1umkUwYm/ao0EWkvExa6GaWBB4BbgaWAneZ2dIJtqsH7gdeK3bIU1GVStLeVMvGPUfCjCEictYVsoe+Auhy9y3uPgQ8Adw2wXb/C/gaMFDEfKdlyex6NqnQRaTMFFLoc4EdOcs7g3VjzOxSYJ67/8vJvpGZ3WtmnWbW2d3dfcphC3Veaz3b9/dzdGh0yl5DRKTUnPFBUTNLAA8DX5psW3d/1N2Xu/vylpaWM33pE1rSWo87dO3VOLqIlI9CCn0XMC9nuS1Yl1UPXAi8ZGbbgCuAVWEeGO1orQfgfQ27iEgZKaTQXwc6zGyhmVUCdwKrsk+6+yF3b3b3dndvB14FbnX3zilJXID2ploqkwkVuoiUlUkL3d1HgPuANcAG4El3X2dmXzGzW6c64OlIJRMsmlWnmS4iUlZShWzk7quB1XnrHjrBtteeeawzt6S1jte3HQg7hojIWRO7M0WzOlrr2XXwKEcGdE0XESkPsS30JWMHRjXTRUTKQ3wLfbZmuohIeYltoc+dUUNtZVKFLiJlI7aFnkgYHbPqVOgiUjZiW+iQuQTAxt0aQxeR8hDrQl8yu56e3kH29w2FHUVEZMrFutDP0yUARKSMqNBFRGIi1oXe2lBFQ3VKhS4iZSHWhW5mLJldz/s6MCoiZSDWhQ7BTJc9R3D3sKOIiEypsij0Q0eH2XtkMOwoIiJTqiwKHXRgVETiL/aFfsGcTKG/s+tQyElERKZW7At9Rm0li1qmsVbXRheRmIt9oQMsX9DI2g8OkE7rwKiIxFd5FHr7TA72D7O5W9MXRSS+yqTQGwHo3K5hFxGJr7Io9PamWpqmVdKpcXQRibGyKHQzY9mCmazdvj/sKCIiU6YsCh0y4+jb9vXTrROMRCSmyqjQM+Po2ksXkbgqm0K/8JzpVKUSGkcXkdgqm0KvTCW4qG2GZrqISGyVTaEDLGufyboPD3F0aDTsKCIiRVdWhb58wUyGR523dx4MO4qISNGVVaEvWzATgLUadhGRGCqrQp9RW0nHrDo6t2mmi4jET1kVOmTmo6/drgt1iUj8lF2hL1vQyOGBETbt1YW6RCReyq7QL2vPjKN36gQjEYmZsiv0+Y21zG6o5t827ws7iohIUZVdoZsZV3c080pXD6MaRxeRGCm7Qge4pqOZg/3DrPtQ9xkVkfgoy0K/anEzAL/Y1BNyEhGR4inLQm+uq2LpnAZ+sak77CgiIkVTloUOmWGXtdsP0D80EnYUEZGiKKjQzWylmW00sy4ze2CC5//EzNab2W/M7HkzW1D8qMV1dUczw6POa1s0fVFE4mHSQjezJPAIcDOwFLjLzJbmbfYmsNzdPw48DXy92EGL7bL2RqpSCY2ji0hsFLKHvgLocvct7j4EPAHclruBu7/o7v3B4qtAW3FjFl91RZIVCxs1ji4isVFIoc8FduQs7wzWncg9wDMTPWFm95pZp5l1dneHX6TXdDSzaW8vuw8NhB1FROSMFfWgqJn9PrAc+MZEz7v7o+6+3N2Xt7S0FPOlT8vVizMZtJcuInFQSKHvAublLLcF68YxsxuBPwNudffB4sSbWufPrqe5rpJfdmkcXUSir5BCfx3oMLOFZlYJ3Amsyt3AzC4B/pZMme8tfsypkUgYVy9u5pebenQ5XRGJvEkL3d1HgPuANcAG4El3X2dmXzGzW4PNvgHUAU+Z2VtmtuoE367kXN3Rwr6+ITbsPhx2FBGRM5IqZCN3Xw2szlv3UM7jG4uc66y5OucyAB87Z3rIaURETl/ZnimaNXt6NUvnNPDMOx+FHUVE5IyUfaED/MdL5/L2zkNs2nMk7CgiIqdNhQ7cdvFckgnj6Td2hh1FROS0qdCBlvoqrlvSwk/e3KWbXohIZKnQA7df2saew4Oaky4ikaVCD1x/wSym11Tww7UadhGRaFKhB6pSSW67+BzWrNvN4YHhsOOIiJwyFXqO2y9tY3Akzb/8RlMYRSR6VOg5Pt42ncWz6jTsIiKRpELPYWbcsayNzu0H2NrTF3YcEZFTokLP8x8umUvC4Eeaky4iEaNCz9PaUM21S2bxg9c+0A2kRSRSVOgT+MJ1i9jXN8QPXvsg7ChnzWja+fKqdWzu7g07ioicJhX6BJYtaOSqxU185+UtDAyPhh3nrNjS3cv3/20bq976MOwoInKaVOgn8MXrO+jpHeTxX5fHXnr2IHDXXu2hi0SVCv0ELj+3iRULG/nOy5vLYi9dhS4SfSr0k7j/hg72HB7kqc4dYUeZctlC39rTx8hoOuQ0InI6VOgnceWiJpYtmMm3X9rM0Ei8S25LUOhDo2l2HDgachoROR0q9JMwM754QwcfHhrghzGfl761p4/zWusAdKMPkYhSoU/ikx3NXDRvBt9+aTPpmF4rvXdwhO4jg9xwQSsAXZq6KBJJKvRJmBn3XL2QD/b38/Km7rDjTIltwXDLRW3Tmd1QrQOjIhGlQi/Ayo/Nprmuin/81fawo0yJ7Pj5wuY6Fs+qY7MKXSSSVOgFqEwluGvFPF7YuJcd+/vDjlN0W7szhb6gqZbFs+ro2tuLezyHl0TiTIVeoLtWzMeAf4rh5QC27etj7owaqiuSLJpVR9/QKB8dGgg7loicIhV6gc6ZUcNNS1t5snNH7E402tLTx8LmaQB0zMrMdNE4ukj0qNBPwWeuaGd/3xCr34nPHY3cna3dvWOFvliFLhJZKvRTcOWiJs5tnsZjr8bn4Oj+viEOD4zQHhR607RKZtRWsCmmhZ5Oe+z+hSWSpUI/BYmE8ftXLODNDw7y7q5DYccpiuwp/+cGhW5mLG6J70yX7/1yC1d99QWODqnUJX5SYQeImtuXtfH1Ne/xzWc3cll7I9t6+ti+rx8MHv3MMmbUVoYd8ZRsHZuyOG1sXUdrHWvW7Qkr0pT68Zsfsq9viJff38vKC+eEHUekqLSHfoqm11Rw+6VtvLSxm2+s2cjL73fjOG9sP8D/+PE7kZvut7Wnj1TCaJtZM7ZuUUsd+/uG2Nc7GGKy4tuxv58NHx0G4Jl3d4ecRqT4tId+Gv7iU0v5wyvbmTuzhtrKzFv4nZc389Vn3uPJzh383mXzQ05YuK09fcxvqiWVPPa7PffAaFNdVVjRiu7nGzL/6rh8YSMvbNjL4MgoValkyKlEikd76KehuiJJR2v9WJkD3HvNuVy5qIkvr1ofqdu4be3pY2HTtHHrxgo9Qj9HIZ5bv4eOWXV8/tpFHBkc4ZWunrAjiRSVCr1IEgnj4U9fTHVFgvufeDMSl9tNp51t+/rGjZ8DnDO9htrKZKymLh7sH+K1rfu5aWkrVy1qpr46xTPvaNhF4kWFXkSzp1fztds/zru7DvO/n90YdpxJ7T48wMBwmoUt4ws9kTAWtdTFqtBf3LiX0bRz09JWKlMJbryglWfX72FYN/OQGFGhF9lvf2w2d18+n7/91y08vba0r6E+0QyXrOw1XeLiufV7mFVfxUVtMwBYeeFsDh0d5tUt+0JOJlI8KvQp8BefWso1Hc386dNvl3Spb5mk0D86NEDv4MjZjlV0A8OjvLSxmxuXtpJIGAC/dV4LtZVJzXaRWFGhT4HqiiTf/YPlXLUoU+o/LNFS39rdR01Fktb66uOeyx4YjcMJRr/avI/+oVFuWto6tq66Isl158/i2XW7GY3pjUvOtg8PHo3tTWCiQoU+RbKlfuWiJv7r02/zoxK8hd22fX20N08b22vNlS30OFwC4Nn1e5hWmeTKRU3j1t984Wx6eofo3LY/pGTxkE47Dz+7kSu/+gJ3f+81dutKnaEpqNDNbKWZbTSzLjN7YILnq8zs/wXPv2Zm7cUOGkU1lUm+9weX8Ylzm/jSU2/z+cfW8vL73SWzF7O1p2/slP98CxprqatK8ZerN/DXz2/iQN/QWU5XHOm08/MNe7h2yazj5pxft2QWVamEhl3OQO/gCJ//x7X89QtdXLukhbd2HOTmb/0rz67TexqGSU8sMrMk8AhwE7ATeN3MVrn7+pzN7gEOuPtiM7sT+Brwe1MROGpqKpP83Wcv46+ef5+nOnfys3W7aZtZw6eXz+PCuQ00Tauiub6K5rrKs3qSy/Bomg/293PLv5s94fOpZILH7lnBt57fxMPPvc+3X9rMp5e3cd35s5hZW8nM2kqm11YwrTJJMmGYHb+XXwre2nmQ7iOD44ZbsqZVpfjkeS2sfucjLmtv5JwZ1cydUUNzXdWE/2qR8Xbs7+dz/9DJpr1HeOhTS/lPV7WzpaeP+594k3sfW8tnrljA3VfMp2laFTNrK8advCZTwyY7Vd3MPgF82d3/fbD8IIC7/2XONmuCbX5lZilgN9DiJ/nmy5cv987OziL8CNExODLKc+v38PivP+CVruNnVyQsU6QVCSMZfAFjZZmwzOOEQcKMhGWfD74wsr2araP8os0ujaSdD/b3883fvYg7lrWdNPfG3Uf47i+28M9v7WJ4dOKPtCKZyZtKJDL5EjaWMRHkS5hheZlys48t533v7PaTVuwEGxw+OsKB/iHe+PObmF5bcdzza9bt5j8/tnbcumTCqEge+1lSycTYe28EP0fO+2wFfA4T/hyT/ECn+ivlbP9S3X1ogITBI3dfyjUdLWPrB0dG+eaajXz3F1tzssGMmgqqK5Jj798J38f8F7KTLk4qjJ2NyV7xizd08DsXnXN639tsrbsvn/C5Agr9DmClu38uWP4McLm735ezzbvBNjuD5c3BNj153+te4F6A+fPnL9u+PT6XoT1Vew8PsOvgUXp6h+jpHWRf7yADw2mG02lGRp2R0TQOZD8ex3GHtGeuYZ52ZzSdWR/8N3Ydmewnmv/R5n/S1akE//3m82ku8PT+fb2DbNvXx8H+YQ70D3Owf4ijQ6MMpzN5R9LOyGgmWzonIzjpIGsm/7GfKZudIH9+xmPbHttmor+guX+OnfF/oS6eN4PPXXPuCX+uwwPD7DpwlA8PZr72HB5keDTNaNozP1M6fdx7n83mY/8/8edwop/jZE55UO4sjOI5PvaLFzLHie67fvGEs6QA3tt9mM17+9jfN0hP7xD7+gYZHE5n3kd8bOhx/J/zvNfMe59K8X05/iUnf9E7L5vPJ89rmXS7iZys0M/qtVzc/VHgUcjsoZ/N1y41sxqqmdVw/OySUtZUVxWra7tkNVRX0DCnggvmNIQdJVbOn93A+bP1np5NhQxq7QLm5Sy3Besm3CYYcpkO6IwNEZGzqJBCfx3oMLOFZlYJ3AmsyttmFfDZ4PEdwAsnGz8XEZHim3TIxd1HzOw+YA2QBP7e3deZ2VeATndfBfwd8JiZdQH7yZS+iIicRQWNobv7amB13rqHch4PAL9b3GgiInIqNDFURCQmVOgiIjGhQhcRiQkVuohITEx6puiUvbBZN3C6p4o2A6V+Q8goZIRo5FTG4lDG4gg74wJ3n/A009AK/UyYWeeJTn0tFVHICNHIqYzFoYzFUcoZNeQiIhITKnQRkZiIaqE/GnaAAkQhI0QjpzIWhzIWR8lmjOQYuoiIHC+qe+giIpJHhS4iEhORK/TJblgdBjP7ezPbG9y5Kbuu0cyeM7NNwf9nhpxxnpm9aGbrzWydmd1fajnNrNrMfm1mbwcZ/2ewfmFw8/Gu4GbklWFlzMmaNLM3zeynpZjRzLaZ2Ttm9paZdQbrSuazzsk5w8yeNrP3zGyDmX2ilHKa2ZLgPcx+HTazPy6ljLkiVeg5N6y+GVgK3GVmS8NNBcD3gZV56x4Annf3DuD5YDlMI8CX3H0pcAXwheC9K6Wcg8D17n4RcDGw0syuIHPT8f/j7ouBA2RuSh62+4ENOculmPE6d784Z850KX3WWd8Cfubu5wMXkXlPSyanu28M3sOLgWVAP/DjUso4jrtH5gv4BLAmZ/lB4MGwcwVZ2oF3c5Y3AnOCx3OAjWFnzMv7z8BNpZoTqAXeAC4nc1ZeaqI/AyFlayPzl/h64KdkbmFaahm3Ac1560rqsyZzZ7OtBJMzSjVnTq7fBl4p5YyR2kMH5gI7cpZ3ButKUau7fxQ83g20hhkml5m1A5cAr1FiOYOhjLeAvcBzwGbgoLuPBJuUwmf+V8B/A9LBchOll9GBZ81sbXBzdiixzxpYCHQD/zcYvvqemU2j9HJm3Qk8HjwuyYxRK/RI8syv8ZKYH2pmdcAPgT9298O5z5VCTncf9cw/b9uAFcD5YebJZ2afAva6+9qws0ziane/lMzw5BfM7JO5T5bCZ03mBjuXAt9290uAPvKGLkokJ8ExkVuBp/KfK5WMEL1CL+SG1aVij5nNAQj+vzfkPJhZBZky/yd3/1GwuuRyArj7QeBFMsMXM4Kbj0P4n/lVwK1mtg14gsywy7corYy4+67g/3vJjPmuoPQ+653ATnd/LVh+mkzBl1pOyPxifMPd9wTLpZgxcoVeyA2rS0XujbM/S2bMOjRmZmTu/brB3R/OeapkcppZi5nNCB7XkBnj30Cm2O8INgs1o7s/6O5t7t5O5s/fC+5+NyWU0cymmVl99jGZsd93KaHPGsDddwM7zGxJsOoGYD0lljNwF8eGW6A0M0broGhwAOIW4H0yY6t/FnaeINPjwEfAMJm9jnvIjKs+D2wCfg40hpzxajL/LPwN8FbwdUsp5QQ+DrwZZHwXeChYfy7wa6CLzD95q8L+zINc1wI/LbWMQZa3g6912b8npfRZ52S9GOgMPvOfADNLLScwDdgHTM9ZV1IZs1869V9EJCaiNuQiIiInoEIXEYkJFbqISEyo0EVEYkKFLiISEyp0EZGYUKGLiMTE/wcJAczPKyseZwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri0fLrhvKqEb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ddb13762-93da-430c-cdc5-ed61810f3ab6"
      },
      "source": [
        "new_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9178321678321678"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p62ELjjaS1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index=str(index)\n",
        "type='decay_145'\n",
        "model='final'\n",
        "path = F\"/content/gdrive/My Drive/\"+model \n",
        "np.save(path+\"/best_accuracy_all_fold_\"+index+\"_\"+model+\"_\"+type+\".npy\",best_accuracy_last)\n",
        "np.save(path+'/final_accuracy_all_fold'+index+\"_\"+model+\"_\"+type+\".npy\",final_accuracy_last)\n",
        "np.save(path+'/history_all_fold_'+index+\"_\"+model+\"_\"+type+\".npy\",history_last)\n",
        "np.save(path+'/answers_all_fold_'+index+\"_\"+model+\"_\"+type+\".npy\",answers_last)\n",
        "np.save(path+'/predictions_all_fold_'+index+\"_\"+model+\"_\"+type+\".npy\",predictions_last)\n",
        "np.save(path+'/predictions_all_best_fold_'+index+\"_\"+model+\"_\"+type+\".npy\",predictions_last_best)\n",
        "np.save(path+'/times_all_fold_'+index+\"_\"+model+\"_\"+type+\".npy\",times_last)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L7NLo1fezlx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}