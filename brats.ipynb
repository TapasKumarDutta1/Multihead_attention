{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQwmEckL2enBGubGxQR+C7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TapasKumarDutta1/Multihead_attention/blob/master/brats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQCxaMJI-mNw"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import h5py\n",
        "from tensorflow.keras.optimizers import *\n",
        "import cv2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import glob, os\n",
        "from matplotlib import pyplot as plt\n",
        "import h5py\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import gc\n",
        "from tensorflow.keras.applications import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.activations import sigmoid\n",
        "from tensorflow.keras.optimizers import *\n",
        "import tensorflow as tf\n",
        "def block(inputs,f):\n",
        "    a=Conv2D(f,3,padding='same')(inputs)\n",
        "    a=BatchNormalization()(a)\n",
        "    a=ReLU()(a)\n",
        "    b=Conv2D(f,3,padding='same')(a)\n",
        "    b=BatchNormalization()(b)\n",
        "    b=ReLU()(b)\n",
        "    c=Conv2D(f,3,padding='same')(b)\n",
        "    c=BatchNormalization()(c)\n",
        "    c=ReLU()(c)\n",
        "    d=Conv2D(f,3,padding='same')(c)\n",
        "    d=BatchNormalization()(d)\n",
        "    d=ReLU()(d)\n",
        "    mid=Concatenate()([a,b,c,d])\n",
        "    \n",
        "    mid=Conv2D(2*f,1,padding='same')(mid)\n",
        "    mid=BatchNormalization()(mid)\n",
        "    mid=ReLU()(mid)\n",
        "    \n",
        "    x=Conv2D(f*2,1)(inputs)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=ReLU()(x)\n",
        "    \n",
        "    x=Add()([mid,x])\n",
        "    \n",
        "    y=Conv2D(f*2,1)(x)\n",
        "    y=BatchNormalization()(y)\n",
        "    y=ReLU()(y)\n",
        "    return y\n",
        "\n",
        "\n",
        "\n",
        "def Global_attention_block(C_A):\n",
        "    \n",
        "    x=Lambda(lambda x: K.mean(x,axis=-1,keepdims=True))  (C_A)\n",
        "    y=Lambda(lambda x: K.max(x,axis=-1,keepdims=True))  (C_A)\n",
        "    \n",
        "    x=Concatenate()([x,y])\n",
        "    x=Activation('relu') (x)\n",
        "    x=Conv2D(1,1, padding='same') (x)\n",
        "    x=Activation('sigmoid') (x)\n",
        "    S_A=Multiply()([x,C_A])\n",
        "    return S_A\n",
        "\n",
        "def self_attention(inp):\n",
        "    shp=inp.shape\n",
        "    a=Conv2D(shp[3]//8,1, padding='same') (inp)\n",
        "    a=Activation('relu') (a)\n",
        "    b=Conv2D(shp[3]//8,1, padding='same') (inp)\n",
        "    b=Activation('relu') (b)\n",
        "    c=Conv2D(shp[3]//8,1, padding='same') (inp)\n",
        "    c=Activation('relu') (c)\n",
        "    \n",
        "    a=Reshape(( shp[1]*shp[2], shp[3]//8))(a)\n",
        "    b=Reshape(( shp[1]*shp[2], shp[3]//8))(b)\n",
        "    b=K.permute_dimensions(b, (0, 2, 1))\n",
        "    c=Reshape(( shp[1]*shp[2], shp[3]//8))(c)\n",
        "    inter=K.batch_dot(a,b)\n",
        "    inter=Activation('softmax') (inter)\n",
        "    out=K.batch_dot(inter,c)\n",
        "    out=Reshape(( shp[1],shp[2], shp[3]//8))(out)\n",
        "    out=Conv2D(shp[3],1, padding='same') (out)\n",
        "    out=Activation('relu') (out)\n",
        "    return out\n",
        "\n",
        "def channel_attention(inputs):\n",
        "    shape=K.int_shape(inputs)\n",
        "    x=MaxPooling2D(pool_size=(shape[1],shape[2])) (inputs)\n",
        "    x=Conv2D(shape[3]//8,1, padding='same',kernel_initializer='he_normal', use_bias=False) (x)\n",
        "    x=Activation('relu') (x)\n",
        "    x=Conv2D(shape[3],1, padding='same',kernel_initializer='he_normal', use_bias=False) (x)\n",
        "    x=Activation('sigmoid') (x)\n",
        "    x=Multiply()([x,inputs])\n",
        "    return x\n",
        "\n",
        "def load_model():   \n",
        "  K.clear_session() \n",
        "  inputs = Input(shape=(224,224,3))\n",
        "  x=Conv2D(16,3,padding='same')(inputs)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=ReLU()(x)\n",
        "  x=MaxPooling2D()(x)\n",
        "  \n",
        "  x=Conv2D(16,3,padding='same')(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=ReLU()(x)\n",
        "  x=MaxPooling2D()(x)\n",
        "    \n",
        "  a1=block(x,32)\n",
        "  x=MaxPooling2D()(a1)\n",
        "\n",
        "  a2=block(x,64)\n",
        "  x=MaxPooling2D()(a2)\n",
        "    \n",
        "  a3=block(x,128)\n",
        "\n",
        "#   a31=self_attention(a3)\n",
        "#   a32=Global_attention_block(a3)\n",
        "#   a3=Add()([a31,a32])\n",
        "#   x=channel_attention(a3)\n",
        "    \n",
        "  x=GlobalMaxPooling2D()(a3)\n",
        "    \n",
        "  x=Dropout(0.5)(x)\n",
        "  x=Dense(2,activation='softmax')(x)\n",
        "  model = Model(inputs=inputs, outputs=x)\n",
        "  \n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.activations import sigmoid\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.applications import *\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.applications import *\n",
        "import pandas as pd\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "def rotate_image(image, angle):\n",
        "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "  return result\n",
        "def Hflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Fliplr(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def Vflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Flipud(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def noise(images):\n",
        "    ls=[]\n",
        "    for i in images:\n",
        "        x = np.random.normal(loc=0, scale=0.05, size=(299,299,3))\n",
        "        ls.append(i+x)\n",
        "    return ls\n",
        "def rotate(images):\n",
        "    ls=[]\n",
        "    for angle in range(-15,15,5):\n",
        "        for image in images:\n",
        "            ls.append(rotate_image(image,angle))\n",
        "    return ls\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "  def __init__(self, images, labels, batch_size=64, image_dimensions = (96 ,96 ,3), shuffle=False, augment=False):\n",
        "    self.labels       = labels              # array of labels\n",
        "    self.images = images        # array of image paths\n",
        "    self.batch_size   = batch_size          # batch size\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.floor(self.labels.shape[0] / self.batch_size))\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    self.indexes = np.arange(self.labels.shape[0])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\t\t# selects indices of data for next batch\n",
        "    indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "    # select data and load images\n",
        "    labels = self.labels.loc[indexes]\n",
        "    img = [self.images[k].astype(np.float32) for k in indexes]\n",
        "    imgH=Hflip(img)\n",
        "    imgV=Vflip(img)\n",
        "    imgR=rotate(img)\n",
        "    images=[]\n",
        "    images.extend(imgH)\n",
        "    images.extend(imgV)\n",
        "    images.extend(imgR)\n",
        "    lbl=labels.copy()\n",
        "    labels=pd.DataFrame()\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    #images = np.array([preprocess_input(img) for img in images])\n",
        "    return np.asarray(images), labels.values\n",
        "\n",
        "\n",
        "best_accuracy_last={}\n",
        "final_accuracy_last={}\n",
        "history_last={}\n",
        "answers_last={}\n",
        "predictions_last={}\n",
        "predictions_last_best={}\n",
        "times_last={}\n",
        "\n",
        "\n",
        "#shuffle samples\n",
        "def unison_shuffled_copies(a, b):\n",
        "    assert len(a) == len(b)\n",
        "    p = np.random.permutation(len(a))\n",
        "    return a[p], b[p]\n",
        "\n",
        "\n",
        "\n",
        "#change targets\n",
        "def change(img):\n",
        "    resized = cv2.resize(img, (224,224), interpolation = cv2.INTER_AREA )\n",
        "    return resized\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#get train and test splits\n",
        "def get_trn_tst(df,tst_fold):\n",
        "  idx=np.asarray(df['fold'])\n",
        "  y=np.asarray(df['label'])\n",
        "  y-=1\n",
        "  img=np.asarray(df['images'])\n",
        "  img1=[]\n",
        "  for i in range(len(img)):\n",
        "        img1.append(change(img[i]))\n",
        "  img1=np.asarray(img1)\n",
        "  del([img])\n",
        "  gc.collect()\n",
        "  trn_y=np.asarray(y[(idx!=tst_fold)])\n",
        "  trn_img=np.asarray(img1[(idx!=tst_fold)])\n",
        "  tst_y=np.asarray(y[(idx==tst_fold)])\n",
        "  tst_img=img1[idx==tst_fold]\n",
        "  trn_img=np.repeat(trn_img.reshape((trn_img.shape[0],224,224,1)),3,axis=3)\n",
        "  tst_img=np.repeat(tst_img.reshape((tst_img.shape[0],224,224,1)),3,axis=3)\n",
        "  return (trn_img.copy(),trn_y.copy()),(tst_img.copy(),tst_y.copy())\n",
        "\n",
        "from pathlib import Path\n",
        "def get_trn_tst(index):\n",
        "    index=str(index-1)\n",
        "    test=[]\n",
        "    for i in np.load('/kaggle/input/2020-stratified-split/test_'+index+'.npy',allow_pickle=True):\n",
        "        if Path(\"../input/brats2020-classification/\"+i+\"_LGG1.npy\").is_file():\n",
        "            test.append(\"../input/brats2020-classification/\"+i+\"_LGG1.npy\")\n",
        "        if Path(\"../input/brats2020-classification/\"+i+\"_LGG2.npy\").is_file():\n",
        "            test.append(\"../input/brats2020-classification/\"+i+\"_LGG2.npy\")\n",
        "        if Path(\"../input/brats2020-classification/\"+i+\"_LGG3.npy\").is_file():\n",
        "            test.append(\"../input/brats2020-classification/\"+i+\"_LGG3.npy\")\n",
        "        if Path(\"../input/brats2020-classification/\"+i+\"_HGG.npy\").is_file():\n",
        "            test.append(\"../input/brats2020-classification/\"+i+\"_HGG.npy\")\n",
        "    train=[]\n",
        "    for i in np.load('/kaggle/input/2020-stratified-split/train_'+index+'.npy',allow_pickle=True):\n",
        "        if Path(\"../input/brats2020-classification/\"+i+\"_LGG1.npy\").is_file():\n",
        "            train.append(\"../input/brats2020-classification/\"+i+\"_LGG1.npy\")\n",
        "        if Path(\"../input/brats2020-classification/\"+i+\"_LGG2.npy\").is_file():\n",
        "            train.append(\"../input/brats2020-classification/\"+i+\"_LGG2.npy\")\n",
        "        if Path(\"../input/brats2020-classification/\"+i+\"_LGG3.npy\").is_file():\n",
        "            train.append(\"../input/brats2020-classification/\"+i+\"_LGG3.npy\")\n",
        "        if Path(\"../input/brats2020-classification/\"+i+\"_HGG.npy\").is_file():\n",
        "            train.append(\"../input/brats2020-classification/\"+i+\"_HGG.npy\")\n",
        "    return train,test\n",
        "def unison_shuffled_copies(a):\n",
        "    p = np.random.permutation(len(a))\n",
        "    return list(np.asarray(a)[p])\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "  def __init__(self, images, batch_size=64, image_dimensions = (96 ,96 ,3), shuffle=False, augment=False):\n",
        "    self.images = images        # array of image paths\n",
        "    self.batch_size   = batch_size          # batch size\n",
        "    self.augment=augment\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.ceil(len(self.images) / self.batch_size))\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    self.indexes = np.arange(len(self.images))\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    max=(index + 1) * self.batch_size\n",
        "    if max>len(self.images):\n",
        "        max=len(self.images)\n",
        "    indexes = self.images[index * self.batch_size : max]\n",
        "    img = [  ]\n",
        "    for k in indexes:\n",
        "        img.append(np.repeat(cv2.resize(np.load(k), (224,224), interpolation = cv2.INTER_AREA ).reshape((224,224,1)),3,axis=-1).astype(np.float32))\n",
        "    imgH=Hflip(img)\n",
        "    imgV=Vflip(img)\n",
        "    imgR=rotate(img)\n",
        "    images=img\n",
        "    if self.augment:\n",
        "        images.extend(imgH)\n",
        "        images.extend(imgV)\n",
        "        images.extend(imgR)\n",
        "    \n",
        "    labels=[]\n",
        "    for i in indexes:\n",
        "        cls1=i.split('_')[-1].split('.')[0]\n",
        "        if cls1[-1]=='G':\n",
        "            labels.append([1,0])\n",
        "        else:\n",
        "            labels.append([0,1])\n",
        "    if self.augment:\n",
        "        labels*=9\n",
        "        labels=np.stack(labels)\n",
        "    return np.asarray(images), np.asarray(labels)\n",
        "def upd(dk,data):\n",
        "    if dk==0:\n",
        "        dk=data\n",
        "    else:\n",
        "        for ky in data.keys():\n",
        "            dk[ky].extend(data[ky])\n",
        "    return dk\n",
        "for index in range(1,6):\n",
        "  best_accuracy_last={}\n",
        "  final_accuracy_last={}\n",
        "  history_last={}\n",
        "  answers_last={}\n",
        "  predictions_last={}\n",
        "  predictions_last_best={}\n",
        "  times_last={}\n",
        "  epoch=50\n",
        "  pre_acc=0\n",
        "  best=0\n",
        "  fold='fold_'+str(index)\n",
        "  trn,tst=get_trn_tst(index)\n",
        "  history_last[fold]=0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  trn=unison_shuffled_copies(trn)\n",
        "  tst=unison_shuffled_copies(tst)\n",
        "\n",
        "\n",
        "\n",
        "  model=load_model()\n",
        "\n",
        "\n",
        "  \n",
        "  #compiling the model\n",
        "  model.compile(optimizer=Adam(1e-3,decay=1e-4), \n",
        "                     loss='categorical_crossentropy', \n",
        "                     metrics=['accuracy'])\n",
        "  train_data = DataGenerator(trn, batch_size=4, augment=True)\n",
        "  test_data = DataGenerator(tst, batch_size=4, augment=False)\n",
        "  ln=len(trn)\n",
        "  # del([trn_x,trn_y,trn,tst])\n",
        "  # gc.collect()\n",
        "  #fitting the model\n",
        "  #timing\n",
        "  start=time.time()\n",
        "  print('training')\n",
        "  hist=model.fit_generator(train_data,epochs=50,steps_per_epoch=ln//4)\n",
        "  history_last[fold]=upd(history_last[fold],hist.history)\n",
        "\n",
        "  end=time.time()\n",
        "  times_last[fold]=end-start\n",
        "\n",
        "  #getting the prediction \n",
        "  pre=model.predict(test_data)\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "  #select the maximum position\n",
        "  pre=np.argmax(pre,1)\n",
        "  predictions_last[fold]=pre\n",
        "\n",
        "  \n",
        "  labels=[]\n",
        "  for i in tst:\n",
        "        cls1=i.split('_')[-1].split('.')[0]\n",
        "        if cls1[-1]=='G':\n",
        "            labels.append(0)\n",
        "        else:\n",
        "            labels.append(1)\n",
        "  \n",
        "  #getting the accuracy\n",
        "  new_acc=accuracy_score(pre,labels)\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  #storing the predictions\n",
        "  final_accuracy_last[fold]=new_acc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #storing the answers\n",
        "  answers_last[fold]=labels\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "  #freeing memory\n",
        "  del([train_data,test_data,labels])\n",
        "  gc.collect()\n",
        "  model.save_weights('weights.hdf5')\n",
        "  plt.plot(history_last[fold]['loss'])\n",
        "  plt.show()\n",
        "  print(new_acc)\n",
        "  index=str(index)\n",
        "  type='final_3535'\n",
        "  model1='final'\n",
        "  np.save(\"best_accuracy_all_fold_\"+index+\"_\"+model1+\"_\"+type+\".npy\",best_accuracy_last)\n",
        "  np.save('final_accuracy_all_fold'+index+\"_\"+model1+\"_\"+type+\".npy\",final_accuracy_last)\n",
        "  np.save('history_all_fold_'+index+\"_\"+model1+\"_\"+type+\".npy\",history_last)\n",
        "  np.save('answers_all_fold_'+index+\"_\"+model1+\"_\"+type+\".npy\",answers_last)\n",
        "  np.save('predictions_all_fold_'+index+\"_\"+model1+\"_\"+type+\".npy\",predictions_last)\n",
        "  np.save('predictions_all_best_fold_'+index+\"_\"+model1+\"_\"+type+\".npy\",predictions_last_best)\n",
        "  np.save('times_all_fold_'+index+\"_\"+model1+\"_\"+type+\".npy\",times_last)\n",
        "  del([model])\n",
        "  gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4fL04rOfE_PB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}