{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fold_2_final.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/data/blob/master/fold_2_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-QYgRhGfGLZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "aaf75da5-cb8c-4db2-8b54-7ef818af3db6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPJzX5fywOe6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3d9172ee-beb9-4a12-e38f-417129ec3829"
      },
      "source": [
        "\n",
        "from keras.optimizers import *\n",
        "import cv2\n",
        "from keras.utils import to_categorical\n",
        "from matplotlib import pyplot as plt\n",
        "import glob, os\n",
        "from matplotlib import pyplot as plt\n",
        "import h5py\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import gc\n",
        "from keras.applications import *\n",
        "from keras.layers import *\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "import keras\n",
        "import pandas as pd\n",
        "from keras.applications.nasnet import NASNetMobile, preprocess_input\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "import h5py\n",
        "from keras.optimizers import Adam\n",
        "import cv2\n",
        "from keras.utils import to_categorical\n",
        "from matplotlib import pyplot as plt\n",
        "import glob, os\n",
        "from matplotlib import pyplot as plt\n",
        "import h5py\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import gc\n",
        "from keras.applications import *\n",
        "from keras.layers import *\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC8imWIHxEHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = F\"/content/gdrive/My Drive/check.npy\" \n",
        "df=np.load(path,allow_pickle=True)\n",
        "df=df.item()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7IAfQuywQmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#shuffle samples\n",
        "def unison_shuffled_copies(a, b):\n",
        "    assert len(a) == len(b)\n",
        "    p = np.random.permutation(len(a))\n",
        "    return a[p], b[p]\n",
        "\n",
        "\n",
        "\n",
        "#change targets\n",
        "def change(img):\n",
        "    resized = cv2.resize(img, (299,299), interpolation = cv2.INTER_AREA )\n",
        "    return resized\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#get train and test splits\n",
        "def get_trn_tst(df,tst_fold):\n",
        "  dimension=224\n",
        "  idx=np.asarray(df['fold'])\n",
        "  y=np.asarray(df['label'])\n",
        "  y-=1\n",
        "  img=np.asarray(df['image'])\n",
        "  img1=[]\n",
        "  img1=np.asarray(img)\n",
        "  del([img])\n",
        "  gc.collect()\n",
        "  trn_y=np.asarray(y[(idx!=tst_fold)])\n",
        "  trn_img=np.asarray(img1[(idx!=tst_fold)])\n",
        "  tst_y=np.asarray(y[(idx==tst_fold)])\n",
        "  tst_img=img1[idx==tst_fold]\n",
        "  trn_img=np.repeat(trn_img.reshape((trn_img.shape[0],dimension,dimension,1)),1,axis=3)\n",
        "  tst_img=np.repeat(tst_img.reshape((tst_img.shape[0],dimension,dimension,1)),1,axis=3)\n",
        "  return (trn_img.copy(),trn_y.copy()),(tst_img.copy(),tst_y.copy())\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNW0pskZwcEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model(last=True):   \n",
        "  inp=Input((224,224,1,))\n",
        "  x=Convolution2D(8,(7,7),activation='relu')(inp)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=MaxPooling2D(2,2)(x)\n",
        "  x=Convolution2D(32,(5,5),activation='relu')(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=MaxPooling2D(2,2)(x)\n",
        "  x=Convolution2D(64,(5,5),activation='relu')(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=MaxPooling2D(2,2)(x)\n",
        "  x=Convolution2D(128,(5,5),activation='relu')(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=MaxPooling2D(2,2)(x)\n",
        "  x=Convolution2D(256,(5,5),activation='relu')(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=MaxPooling2D(2,2)(x)\n",
        "  x=GlobalAveragePooling2D()(x)\n",
        "  x=Reshape((1,1,256))(x)\n",
        "  x=Flatten()(x)\n",
        "  x=Dense(512,activation='sigmoid')(x)\n",
        "  x=Dropout(0.5)(x)\n",
        "  x=Dense(3,activation='softmax')(x)\n",
        "  model=Model(inputs=inp,outputs=x)\n",
        "  return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIQSvrhBwdnu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "outputId": "fd23b395-0ddb-4381-bada-783d2b7b6b85"
      },
      "source": [
        "mod=load_model()\n",
        "mod.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 1)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 218, 218, 8)       400       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 218, 218, 8)       32        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 109, 109, 8)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 105, 105, 32)      6432      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 105, 105, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 52, 52, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 48, 48, 64)        51264     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 48, 48, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 20, 20, 128)       204928    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 20, 20, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 10, 10, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 6, 6, 256)         819456    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 6, 6, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 1539      \n",
            "=================================================================\n",
            "Total params: 1,217,555\n",
            "Trainable params: 1,216,579\n",
            "Non-trainable params: 976\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWXwzoslwfCL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import pandas as pd\n",
        "from keras.applications.nasnet import NASNetMobile, preprocess_input\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "def rotate_image(image, angle):\n",
        "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "  return result\n",
        "def Hflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Fliplr(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def Vflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Flipud(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def noise(images):\n",
        "    ls=[]\n",
        "    for i in images:\n",
        "        x = np.random.normal(loc=0, scale=0.05, size=(dimension,dimension,3))\n",
        "        ls.append(i+x)\n",
        "    return ls\n",
        "def rotate(images):\n",
        "    ls=[]\n",
        "    for angle in range(-15,20,5):\n",
        "        for image in images:\n",
        "            ls.append(rotate_image(image,angle).reshape((224,224,1)))\n",
        "    return ls\n",
        "\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "  def __init__(self, images, labels, batch_size=64, image_dimensions = (96 ,96 ,3), shuffle=False, augment=False):\n",
        "    self.labels       = labels              # array of labels\n",
        "    self.images = images        # array of image paths\n",
        "    self.batch_size   = batch_size          # batch size\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.floor(self.labels.shape[0] / self.batch_size))\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    self.indexes = np.arange(self.labels.shape[0])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\t\t# selects indices of data for next batch\n",
        "    indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "    # select data and load images\n",
        "    labels = self.labels.loc[indexes]\n",
        "    img = [self.images[k].astype(np.float32) for k in indexes]\n",
        "    imgH=Hflip(img)\n",
        "    imgV=Vflip(img)\n",
        "    imgR=rotate(img)\n",
        "    images=[]\n",
        "    images.extend(imgH)\n",
        "    images.extend(imgV)\n",
        "    images.extend(imgR)\n",
        "    lbl=labels.copy()\n",
        "    labels=pd.DataFrame()\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    img=np.asarray(images)\n",
        "    #images = np.array([preprocess_input(img) for img in images])\n",
        "    return img, labels"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC-Dm3ulwgVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "best_accuracy_last={}\n",
        "final_accuracy_last={}\n",
        "history_last={}\n",
        "answers_last={}\n",
        "predictions_last={}\n",
        "predictions_last_best={}\n",
        "times_last={}\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvsVb2H2whrN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "923a2c0d-fe7e-4aa4-9c20-a806b83c3c04"
      },
      "source": [
        "  def upd(dk,data):\n",
        "    if dk==0:\n",
        "        dk=data\n",
        "    else:\n",
        "        for ky in data.keys():\n",
        "            dk[ky].extend(data[ky])\n",
        "    return dk\n",
        "  index=2\n",
        "  epoch=75\n",
        "  pre_acc=0\n",
        "  best=0\n",
        "  fold='fold_'+str(index)\n",
        "  trn,tst=get_trn_tst(df,index)\n",
        "  history_last[fold]=0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  trn_x,trn_y=unison_shuffled_copies(trn[0],trn[1])\n",
        "  tst_x,tst_y=unison_shuffled_copies(tst[0],tst[1])\n",
        "\n",
        "\n",
        "\n",
        "  model=load_model(last=False)\n",
        "\n",
        "\n",
        "  \n",
        "  #compiling the model\n",
        "  model.compile(optimizer=Adam(1e-3,decay=1e-4), \n",
        "                     loss='categorical_crossentropy', \n",
        "                     metrics=['accuracy'])\n",
        "  train_data = DataGenerator(trn_x,pd.get_dummies(trn_y), batch_size=4, augment=True)\n",
        "  ln=len(trn_y)\n",
        "  del([trn_x,trn_y,trn,tst])\n",
        "  gc.collect()\n",
        "  #fitting the model\n",
        "  #timing\n",
        "  start=time.time()\n",
        "  for i in range(epoch):\n",
        "      hist=model.fit_generator(train_data,epochs=1,steps_per_epoch=ln//4)\n",
        "      history_last[fold]=upd(history_last[fold],hist.history)\n",
        "\n",
        "  end=time.time()\n",
        "  times_last[fold]=end-start\n",
        "\n",
        "  #getting the prediction \n",
        "  pre=model.predict(tst_x)\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "  #select the maximum position\n",
        "  pre=np.argmax(pre,1)\n",
        "  predictions_last[fold]=pre\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "  #getting the accuracy\n",
        "  new_acc=accuracy_score(pre,tst_y)\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  #storing the predictions\n",
        "  final_accuracy_last[fold]=new_acc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #storing the answers\n",
        "  answers_last[fold]=tst_y\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "  #freeing memory\n",
        "  del([tst_x,tst_y])\n",
        "  gc.collect()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "596/596 [==============================] - 57s 96ms/step - loss: 0.7194 - accuracy: 0.6996\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 0.4576 - accuracy: 0.8023\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 0.3285 - accuracy: 0.8599\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 0.2365 - accuracy: 0.9078\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 0.1616 - accuracy: 0.9391\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 0.1202 - accuracy: 0.9562\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 0.0584 - accuracy: 0.9797\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 0.0297 - accuracy: 0.9893\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 0.0122 - accuracy: 0.9966\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 0.0904 - accuracy: 0.9713\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 0.0216 - accuracy: 0.9933\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 0.0029 - accuracy: 0.9998\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 7.5593e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 3.6349e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 2.0964e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 1.4855e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 1.0266e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 8.1750e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 6.0219e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 4.6383e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 3.3804e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 2.4161e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 1.7643e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 1.3226e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 1.1310e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 9.2350e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 7.4566e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 4.5472e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 2.7687e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 3.1396e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 1.9725e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 1.1240e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 1.1641e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 0.0731 - accuracy: 0.9817\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 0.0093 - accuracy: 0.9965\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 4.1011e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 2.1948e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 1.3001e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 1.1211e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 7.1173e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 5.1698e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 3.8849e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 3.1968e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 2.1279e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 2.0137e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 1.1275e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 9.4871e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 7.1532e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 5.7063e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 4.6120e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 3.8526e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 2.5750e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 2.1497e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 2.4753e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 0.0307 - accuracy: 0.9925\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 50s 83ms/step - loss: 0.0018 - accuracy: 0.9994\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 50s 83ms/step - loss: 3.5178e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 50s 83ms/step - loss: 1.9536e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 1.0361e-04 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 5.9492e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 4.7032e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 4.3826e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 2.5546e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 2.4607e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 2.0043e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 1.2229e-05 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 9.8496e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 8.1529e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 5.6367e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 3.8250e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 3.3571e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 3.9817e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 2.4335e-06 - accuracy: 1.0000\n",
            "Epoch 1/1\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 1.3842e-06 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "214"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFQlBar9Kp7y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "7272beab-e95f-422b-a202-898d812a474a"
      },
      "source": [
        "plt.plot(history_last[fold]['loss'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6356ff6898>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri0fLrhvKqEb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "87ea0006-e36d-4b3f-fab3-64423292c68c"
      },
      "source": [
        "new_acc"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.898379970544919"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p62ELjjaS1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index=str(index)\n",
        "type='decay_145'\n",
        "model='final'\n",
        "path = F\"/content/gdrive/My Drive/\"+model \n",
        "np.save(path+\"/best_accuracy_all_fold_\"+index+\"_\"+model+\"_\"+type+\".npy\",best_accuracy_last)\n",
        "np.save(path+'/final_accuracy_all_fold'+index+\"_\"+model+\"_\"+type+\".npy\",final_accuracy_last)\n",
        "np.save(path+'/history_all_fold_'+index+\"_\"+model+\"_\"+type+\".npy\",history_last)\n",
        "np.save(path+'/answers_all_fold_'+index+\"_\"+model+\"_\"+type+\".npy\",answers_last)\n",
        "np.save(path+'/predictions_all_fold_'+index+\"_\"+model+\"_\"+type+\".npy\",predictions_last)\n",
        "np.save(path+'/predictions_all_best_fold_'+index+\"_\"+model+\"_\"+type+\".npy\",predictions_last_best)\n",
        "np.save(path+'/times_all_fold_'+index+\"_\"+model+\"_\"+type+\".npy\",times_last)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L7NLo1fezlx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}