{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    train_labels = pd.read_csv('/kaggle/input/data-science-bowl-2019/train_labels.csv',nrows=100000)\n",
    "    specs = pd.read_csv('/kaggle/input/data-science-bowl-2019/specs.csv',nrows=100000)\n",
    "    sample_submission = pd.read_csv('/kaggle/input/data-science-bowl-2019/sample_submission.csv',nrows=100000)\n",
    "    train = pd.read_csv('/kaggle/input/data-science-bowl-2019/train.csv',nrows=100000)\n",
    "    test = pd.read_csv('/kaggle/input/data-science-bowl-2019/test.csv',nrows=100000)\n",
    "    return train, test, train_labels, specs, sample_submission\n",
    "\n",
    "def encode_title(train, test, train_labels):\n",
    "    train['title_event_code'] = train['title'].astype(str)+train['event_code'].astype(str)\n",
    "    test['title_event_code'] = test['title'].astype(str)+test['event_code'].astype(str)\n",
    "    all_title_event_code = list(set(train[\"title_event_code\"]).union(set(test[\"title_event_code\"])))\n",
    "    list_of_user_activities = list(set(train['title']).union(set(test['title'])))\n",
    "    list_of_event_code = list(set(train['event_code']).union(set(test['event_code'])))\n",
    "    list_of_event_id = list(set(train['event_id']).union(set(test['event_id'])))\n",
    "    list_of_worlds = list(set(train['world']).union(set(test['world'])))\n",
    "    activities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n",
    "    activities_labels = dict(zip(np.arange(len(list_of_user_activities)), list_of_user_activities))\n",
    "    activities_world = dict(zip(list_of_worlds, np.arange(len(list_of_worlds))))\n",
    "    assess_titles = list(set(train[train['type'] == 'Assessment']['title'].value_counts().index).union(set(test[test['type'] == 'Assessment']['title'].value_counts().index)))\n",
    "    return train, test, train_labels, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code\n",
    "\n",
    "\n",
    "train, test, train_labels, specs, sample_submission = read_data()\n",
    "train, test, train_labels, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code=encode_title(train,test,train_labels)\n",
    "win_code={col:4100 for col in ['Mushroom Sorter (Assessment)',\n",
    "       'Cauldron Filler (Assessment)', 'Cart Balancer (Assessment)',\n",
    "       'Chest Sorter (Assessment)']}\n",
    "win_code['Bird Measurer (Assessment)']=4110\n",
    "def get_train_and_test(train, test):\n",
    "    compiled_train = []\n",
    "    compiled_test = []\n",
    "    compiled_val=[]\n",
    "    for i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort = False)), total = 17000):\n",
    "        compiled_train += get_data(user_sample)\n",
    "    for ins_id, user_sample in tqdm(test.groupby('installation_id', sort = False), total = 1000):\n",
    "        test_data,val_data = get_data(user_sample, test_set = True)\n",
    "        compiled_test.append(test_data)\n",
    "        compiled_val+=(val_data)\n",
    "    reduce_train = pd.DataFrame(compiled_train)\n",
    "    reduce_test = pd.DataFrame(compiled_test)\n",
    "    reduce_val = pd.DataFrame(compiled_val)\n",
    "    return reduce_train, reduce_test,reduce_val\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# import catboost as cat\n",
    "import time\n",
    "from collections import Counter\n",
    "import datetime\n",
    "# from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit, RepeatedStratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import linear_model\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "pd.options.display.precision = 15\n",
    "from collections import defaultdict\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "def get_data(user_sample, test_set=False):\n",
    "    '''\n",
    "    The user_sample is a DataFrame from train or test where the only one \n",
    "    installation_id is filtered\n",
    "    And the test_set parameter is related with the labels processing, that is only requered\n",
    "    if test_set=False\n",
    "    '''\n",
    "    all_assessments=[]\n",
    "    event_code_count: Dict[str, int] = {ev: 0 for ev in list_of_event_code}\n",
    "    event_id_count: Dict[str, int] = {eve: 0 for eve in list_of_event_id}\n",
    "    title_count: Dict[str, int] = {eve: 0 for eve in activities_labels.values()} \n",
    "    title_event_code_count: Dict[str, int] = {t_eve: 0 for t_eve in all_title_event_code}\n",
    "    \n",
    "    \n",
    "    \n",
    "    ass_try_non_rec=0\n",
    "    ass_true_non_rec=0\n",
    "    ass_false_non_rec=0\n",
    "\n",
    "\n",
    "    ass_try_rec=0\n",
    "    ass_true_rec=0\n",
    "    ass_false_rec=0\n",
    "  \n",
    "  \n",
    "    try_non_rec=0\n",
    "    true_non_rec=0\n",
    "    false_non_rec=0\n",
    "\n",
    "    cnt=0\n",
    "    try_rec=0\n",
    "    true_rec=0\n",
    "    false_rec=0\n",
    "    cum_acc=0\n",
    "    for i, session in user_sample.groupby('game_session', sort=False):\n",
    "        session_type = session['type'].iloc[0]\n",
    "        session_title = session['title'].iloc[0]\n",
    "        \n",
    "        rec=session.loc[session['event_code'].isin([4100,4110])]\n",
    "        non_rec=session.loc[~(session['event_code'].isin([4100,4110]))]\n",
    "        if (session_type == 'Assessment') & (test_set or len(session)>1):\n",
    "            features={}\n",
    "            all_attempts = session.loc[session['event_code']==win_code[session_title]]\n",
    "            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n",
    "            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n",
    "            features.update(event_code_count.copy())\n",
    "            features.update(event_id_count.copy())\n",
    "            features.update(title_count.copy())\n",
    "            features.update(title_event_code_count.copy())\n",
    "            features['true_rec_ass']=ass_true_rec\n",
    "            features['false_rec_ass']=ass_false_rec\n",
    "            features['tot_rec_ass']=ass_try_rec\n",
    "    \n",
    "      \n",
    "            features['true_non_rec_ass']=ass_true_non_rec\n",
    "            features['false_non_rec_ass']=ass_false_non_rec\n",
    "            features['tot_non_rec_ass']=ass_try_non_rec\n",
    "    \n",
    "      \n",
    "            features['true_rec_non_ass']=true_rec\n",
    "            features['false_rec_non_ass']=false_rec\n",
    "            features['tot_rec_non_ass']=try_rec\n",
    "    \n",
    "      \n",
    "            features['true_non_rec']=true_non_rec\n",
    "            features['false_non_rec']=false_non_rec\n",
    "            features['tot_non_rec']=try_non_rec\n",
    "            if cnt!=0:\n",
    "                features['accuracy_cum']=cum_acc/cnt\n",
    "            else:\n",
    "                features['accuracy_cum']=0\n",
    "            cnt+=1\n",
    "            features['installation_id'] = session['installation_id'].iloc[-1]\n",
    "            features['session_title'] = session['title'].iloc[0]\n",
    "            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "            cum_acc+=accuracy\n",
    "            if accuracy == 0:\n",
    "                features['accuracy_group'] = 0\n",
    "            elif accuracy == 1:\n",
    "                features['accuracy_group'] = 3\n",
    "            elif accuracy == 0.5:\n",
    "                features['accuracy_group'] = 2\n",
    "            else:\n",
    "                features['accuracy_group'] = 1\n",
    "            true=rec.event_data.str.contains('true').sum()\n",
    "            false=rec.event_data.str.contains('false').sum()\n",
    "            tot=true+false\n",
    "        \n",
    "            if test_set:\n",
    "                all_assessments.append(features)\n",
    "            elif true_attempts+false_attempts > 0:\n",
    "                \n",
    "                ass_true_rec+=true\n",
    "                ass_false_rec+=false\n",
    "                ass_try_rec=ass_false_rec+ass_true_rec\n",
    "                \n",
    "                \n",
    "                all_assessments.append(features)\n",
    "      \n",
    "            else:\n",
    "                ass_true_non_rec+=non_rec.event_data.str.contains('true').sum()\n",
    "                ass_false_non_rec+=non_rec.event_data.str.contains('false').sum()\n",
    "                ass_tot_non_rec=ass_true_non_rec+ass_false_non_rec\n",
    "      \n",
    "    \n",
    "    \n",
    "            \n",
    "        \n",
    "        def update_counters(counter: dict, col: str):\n",
    "                num_of_session_count = Counter(session[col])\n",
    "                for k in num_of_session_count.keys():\n",
    "                    x = k\n",
    "                    counter[x] += num_of_session_count[k]\n",
    "                return counter\n",
    "            \n",
    "        event_code_count = update_counters(event_code_count, \"event_code\")\n",
    "        event_id_count = update_counters(event_id_count, \"event_id\")\n",
    "        title_count = update_counters(title_count, 'title')\n",
    "        title_event_code_count = update_counters(title_event_code_count, 'title_event_code')\n",
    "        true_non_rec+=(non_rec['event_data'].str.contains('true')).sum()\n",
    "        false_non_rec+=(non_rec['event_data'].str.contains('false')).sum()\n",
    "        tot_non_rec=true_non_rec+false_non_rec\n",
    "        true_rec+=(rec['event_data'].str.contains('true')).sum()\n",
    "        false_rec+=(rec['event_data'].str.contains('false')).sum()\n",
    "        tot_rec=false_rec+true_rec\n",
    "    if test_set:\n",
    "        return all_assessments[-1],all_assessments[:-1]\n",
    "    return all_assessments\n",
    "reduce_train, reduce_test, reduce_val= get_train_and_test(train, test)\n",
    "for df in [reduce_train,reduce_test,reduce_val]:\n",
    "    df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in df.columns]\n",
    "import lightgbm as lgb\n",
    "trn_ft=lgb.Dataset(reduce_train.select_dtypes(exclude=object).drop(['accuracy_group'],1),reduce_train['accuracy_group'])\n",
    "val_ft=lgb.Dataset(reduce_val.select_dtypes(exclude=object).drop(['accuracy_group'],1),reduce_val['accuracy_group'])\n",
    "mod=lgb.train( {'feature_fraction': 0.7975023410800904,'n_estimators':7297,'learning_rate':0.001,\n",
    "  'max_depth': 14,\n",
    "  'subsample': 0.7531064105216918},trn_ft)\n",
    "pre=mod.predict(reduce_test.select_dtypes(exclude=object).drop(['accuracy_group'],1))\n",
    "x,y,z=1.21519937, 1.70523477, 2.25945307\n",
    "res=[]\n",
    "for i in pre:\n",
    "        if i<x:\n",
    "            res.append(0)\n",
    "        elif i<y:\n",
    "            res.append(1)\n",
    "        elif i<z:\n",
    "            res.append(2)\n",
    "        else:\n",
    "            res.append(3)\n",
    "\n",
    "\n",
    "sample_submission['accuracy_group']=res\n",
    "sample_submission.to_csv('submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
