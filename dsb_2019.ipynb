{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9a8ef21f8cf3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitles_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtitles_demap\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mworld_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mevent_code_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mevent_code_demap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspecs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_submission\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitles_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtitles_demap\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mworld_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mevent_code_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mevent_code_demap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencode_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-9a8ef21f8cf3>\u001b[0m in \u001b[0;36mread_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# Reading train.csv file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/kaggle/input/data-science-bowl-2019/train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Reading test.csv file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "def read_data():\n",
    "    # Reading train.csv file\n",
    "    train = pd.read_csv('/kaggle/input/data-science-bowl-2019/train.csv')\n",
    "    \n",
    "    # Reading test.csv file\n",
    "    test = pd.read_csv('/kaggle/input/data-science-bowl-2019/test.csv')\n",
    "    \n",
    "    # Reading train_labels.csv file\n",
    "    train_labels = pd.read_csv('/kaggle/input/data-science-bowl-2019/train_labels.csv')\n",
    "    \n",
    "    # Reading specs.csv file\n",
    "    specs = pd.read_csv('/kaggle/input/data-science-bowl-2019/specs.csv')\n",
    "\n",
    "    # Reading sample_submission.csv file\n",
    "    sample_submission = pd.read_csv('/kaggle/input/data-science-bowl-2019/sample_submission.csv')\n",
    "    return train, test, train_labels, specs, sample_submission\n",
    "\n",
    "def encode_title(train, test, train_labels):\n",
    "    # encode title\n",
    "    train['title_event_code'] = train['title'].astype(str)+train['event_code'].astype(str)\n",
    "    test['title_event_code'] = test['title'].astype(str)+test['event_code'].astype(str)\n",
    "    \n",
    "    titles = list(set(train['title'].unique()).union(set(test['title'].unique())))\n",
    "    event_code = list(set(train['event_code'].unique()).union(set(test['event_code'].unique())))\n",
    "    event_id = list(set(train['event_id'].unique()).union(set(test['event_id'].unique())))\n",
    "    worlds = list(set(train['world'].unique()).union(set(test['world'].unique())))\n",
    "    title_code = list(set(train['title_event_code'].unique()).union(set(test['title_event_code'].unique())))\n",
    "    \n",
    "    \n",
    "    \n",
    "    event_code_map = dict(zip(event_code, np.arange(len(event_code))))\n",
    "    \n",
    "    title_map = dict(zip(titles, np.arange(len(titles))))\n",
    "    title_demap = dict(zip(np.arange(len(titles)),titles ))\n",
    "    \n",
    "    event_id_map = dict(zip(event_id,np.arange(len(event_id))))\n",
    "    world_map = dict(zip(worlds, np.arange(len(worlds))))\n",
    "    \n",
    "    title_code_map=dict(zip(title_code,np.arange(len(title_code))))\n",
    "    title_code_demap=dict(zip(np.arange(len(title_code)),title_code))\n",
    "    \n",
    "    \n",
    "    # replace the text titles with the number titles from the dict\n",
    "    train['title'] = train['title'].map(title_map)\n",
    "    test['title'] = test['title'].map(title_map)\n",
    "    train['world'] = train['world'].map(world_map)\n",
    "    test['world'] = test['world'].map(world_map)\n",
    "    train_labels['title'] = train_labels['title'].map(title_map)\n",
    "    \n",
    "    train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "    test['timestamp'] = pd.to_datetime(test['timestamp'])\n",
    "    \n",
    "    \n",
    "    win_code={col:4100 for col in train.loc[train['type']=='Assessment']['title'].unique()}\n",
    "    win_code[title_map['Bird Measurer (Assessment)']]=4110\n",
    "    \n",
    "    return train, test, train_labels, title_map,title_demap,world_map,title_code,win_code,event_code_map,event_id_map\n",
    "\n",
    "train, test, train_labels, specs, sample_submission = read_data()\n",
    "train, test, train_labels, title_map,title_demap,world_map,title_code,win_code,event_code_map,event_id_map = encode_title(train, test, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_test(train, test):\n",
    "    compiled_train = []\n",
    "    compiled_test = []\n",
    "    compiled_val=[]\n",
    "    for i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort = False))):\n",
    "        compiled_train += get_data(user_sample)\n",
    "    for ins_id, user_sample in tqdm(test.groupby('installation_id', sort = False)):\n",
    "        test_data,val_data = get_data(user_sample, test_set = True)\n",
    "        compiled_test.append(test_data)\n",
    "        compiled_val+=(val_data)\n",
    "    reduce_train = pd.DataFrame(compiled_train)\n",
    "    reduce_test = pd.DataFrame(compiled_test)\n",
    "    reduce_val = pd.DataFrame(compiled_val)\n",
    "    categoricals = ['session_title']\n",
    "    return reduce_train, reduce_test,reduce_val\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "from collections import Counter\n",
    "import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit, RepeatedStratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import linear_model\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "pd.options.display.precision = 15\n",
    "from collections import defaultdict\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "def get_data(user_sample, test_set=False):\n",
    "    all_assessments=[]\n",
    "    event_code_count: Dict[str, int] = {ev: 0 for ev in list(event_code_map.keys())}\n",
    "    event_id_count: Dict[str, int] = {eve: 0 for eve in list(event_id_map.keys())}\n",
    "    title_count: Dict[str, int] = {eve: 0 for eve in list(title_map.keys())} \n",
    "    title_code_count: Dict[str, int] = {t_eve: 0 for t_eve in title_code}\n",
    "    \n",
    "    \n",
    "    \n",
    "    ass_try_non_rec=0\n",
    "    ass_true_non_rec=0\n",
    "    ass_false_non_rec=0\n",
    "\n",
    "\n",
    "    ass_try_rec=0\n",
    "    ass_true_rec=0\n",
    "    ass_false_rec=0\n",
    "  \n",
    "  \n",
    "    try_non_rec=0\n",
    "    true_non_rec=0\n",
    "    false_non_rec=0\n",
    "\n",
    "    cnt=0\n",
    "    try_rec=0\n",
    "    true_rec=0\n",
    "    false_rec=0\n",
    "    cum_acc=0\n",
    "    for i, session in user_sample.groupby('game_session', sort=False):\n",
    "        \n",
    "        session_type = session['type'].iloc[0]\n",
    "        session_title = session['title'].iloc[0]\n",
    "        session_title_text = title_demap[session_title]\n",
    "                    \n",
    "        rec=session.loc[session['event_code'].isin([4100,4110])]\n",
    "        non_rec=session.loc[~(session['event_code'].isin([4100,4110]))]\n",
    "        \n",
    "        if (session_type == 'Assessment') & (test_set or len(session)>1):\n",
    "            features={}\n",
    "            all_attempts = session.loc[session['event_code']==win_code[session_title]]\n",
    "            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n",
    "            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n",
    "            features.update(event_code_count.copy())\n",
    "            features.update(event_id_count.copy())\n",
    "            features.update(title_count.copy())\n",
    "            features.update(title_code_count.copy())\n",
    "            \n",
    "            \n",
    "            #recorded_assessments\n",
    "            features['true_rec_ass']=ass_true_rec\n",
    "            features['false_rec_ass']=ass_false_rec\n",
    "            features['tot_rec_ass']=ass_try_rec\n",
    "    \n",
    "            #non_recorded assessmnents\n",
    "            features['true_non_rec_ass']=ass_true_non_rec\n",
    "            features['false_non_rec_ass']=ass_false_non_rec\n",
    "            features['tot_non_rec_ass']=ass_try_non_rec\n",
    "    \n",
    "            #all recorded\n",
    "            features['true_rec_non_ass']=true_rec\n",
    "            features['false_rec_non_ass']=false_rec\n",
    "            features['tot_rec_non_ass']=try_rec\n",
    "    \n",
    "            #all non recorded\n",
    "            features['true_non_rec']=true_non_rec\n",
    "            features['false_non_rec']=false_non_rec\n",
    "            features['tot_non_rec']=try_non_rec\n",
    "            if cnt!=0:\n",
    "                features['accuracy_cum']=cum_acc/cnt\n",
    "            else:\n",
    "                features['accuracy_cum']=0\n",
    "            cnt+=1\n",
    "            features['installation_id'] = session['installation_id'].iloc[-1]\n",
    "            features['session_title'] = session['title'].iloc[0]\n",
    "            \n",
    "            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "            cum_acc+=accuracy\n",
    "            if accuracy == 0:\n",
    "                features['accuracy_group'] = 0\n",
    "            elif accuracy == 1:\n",
    "                features['accuracy_group'] = 3\n",
    "            elif accuracy == 0.5:\n",
    "                features['accuracy_group'] = 2\n",
    "            else:\n",
    "                features['accuracy_group'] = 1\n",
    "            true=rec.event_data.str.contains('true').sum()\n",
    "            false=rec.event_data.str.contains('false').sum()\n",
    "            tot=true+false\n",
    "        \n",
    "            if test_set:\n",
    "                all_assessments.append(features)\n",
    "            elif true_attempts+false_attempts > 0:\n",
    "                \n",
    "                ass_true_rec+=true\n",
    "                ass_false_rec+=false\n",
    "                ass_try_rec=ass_false_rec+ass_true_rec\n",
    "                \n",
    "                \n",
    "                all_assessments.append(features)\n",
    "      \n",
    "            else:\n",
    "            #non rec ass\n",
    "                ass_true_non_rec+=non_rec.event_data.str.contains('true').sum()\n",
    "                ass_false_non_rec+=non_rec.event_data.str.contains('false').sum()\n",
    "                ass_tot_non_rec=ass_true_non_rec+ass_false_non_rec\n",
    "      \n",
    "    \n",
    "    \n",
    "            \n",
    "        \n",
    "        # this piece counts how many actions was made in each event_code so far\n",
    "        def update_counters(counter: dict, col: str):\n",
    "                num_of_session_count = Counter(session[col])\n",
    "                for k in num_of_session_count.keys():\n",
    "                    x = k\n",
    "                    if col == 'title':\n",
    "                        x = title_demap[k]\n",
    "                    counter[x] += num_of_session_count[k]\n",
    "                return counter\n",
    "            \n",
    "        event_code_count = update_counters(event_code_count, \"event_code\")\n",
    "        event_id_count = update_counters(event_id_count, \"event_id\")\n",
    "        title_count = update_counters(title_count, 'title')\n",
    "        title_code_count = update_counters(title_code_count, 'title_event_code')\n",
    "    \n",
    "        #non rec\n",
    "        true_non_rec+=(non_rec['event_data'].str.contains('true')).sum()\n",
    "        false_non_rec+=(non_rec['event_data'].str.contains('false')).sum()\n",
    "        tot_non_rec=true_non_rec+false_non_rec\n",
    "        #rec\n",
    "        true_rec+=(rec['event_data'].str.contains('true')).sum()\n",
    "        false_rec+=(rec['event_data'].str.contains('false')).sum()\n",
    "        tot_rec=false_rec+true_rec\n",
    "        # counts how many actions the player has done so far, used in the feature of the same name\n",
    "                        \n",
    "    # if it't the test_set, only the last assessment must be predicted, the previous are scraped\n",
    "    if test_set:\n",
    "        return all_assessments[-1],all_assessments[:-1]\n",
    "    # in the train_set, all assessments goes to the dataset\n",
    "    return all_assessments\n",
    "reduce_train, reduce_test, reduce_val= get_train_and_test(train, test)\n",
    "reduce_test.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in reduce_test.columns]\n",
    "reduce_train.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in reduce_train.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "trn_ft=lgb.Dataset(reduce_train.select_dtypes(exclude=object).drop(['accuracy_group'],1),reduce_train['accuracy_group'])\n",
    "val_ft=lgb.Dataset(reduce_val.select_dtypes(exclude=object).drop(['accuracy_group'],1),reduce_val['accuracy_group'])\n",
    "mod=lgb.train( {'feature_fraction': 0.7975023410800904,'n_estimators':7297,'learning_rate':0.001,\n",
    "  'max_depth': 14,\n",
    "  'subsample': 0.7531064105216918},trn_ft)\n",
    "pre=mod.predict(reduce_test.select_dtypes(exclude=object).drop(['accuracy_group'],1))\n",
    "x,y,z=1.21519937, 1.70523477, 2.25945307\n",
    "res=[]\n",
    "for i in pre:\n",
    "        if i<x:\n",
    "            res.append(0)\n",
    "        elif i<y:\n",
    "            res.append(1)\n",
    "        elif i<z:\n",
    "            res.append(2)\n",
    "        else:\n",
    "            res.append(3)\n",
    "\n",
    "\n",
    "sample_submission['accuracy_group']=res\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission['accuracy_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
