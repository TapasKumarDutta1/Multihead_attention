{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    print('Reading train.csv file....')\n",
    "    train = pd.read_csv('/kaggle/input/data-science-bowl-2019/train.csv')\n",
    "    print('Training.csv file have {} rows and {} columns'.format(train.shape[0], train.shape[1]))\n",
    "\n",
    "    print('Reading test.csv file....')\n",
    "    test = pd.read_csv('/kaggle/input/data-science-bowl-2019/test.csv')\n",
    "    print('Test.csv file have {} rows and {} columns'.format(test.shape[0], test.shape[1]))\n",
    "\n",
    "    print('Reading train_labels.csv file....')\n",
    "    train_labels = pd.read_csv('/kaggle/input/data-science-bowl-2019/train_labels.csv')\n",
    "    print('Train_labels.csv file have {} rows and {} columns'.format(train_labels.shape[0], train_labels.shape[1]))\n",
    "\n",
    "    print('Reading specs.csv file....')\n",
    "    specs = pd.read_csv('/kaggle/input/data-science-bowl-2019/specs.csv')\n",
    "    print('Specs.csv file have {} rows and {} columns'.format(specs.shape[0], specs.shape[1]))\n",
    "\n",
    "    print('Reading sample_submission.csv file....')\n",
    "    sample_submission = pd.read_csv('/kaggle/input/data-science-bowl-2019/sample_submission.csv')\n",
    "    print('Sample_submission.csv file have {} rows and {} columns'.format(sample_submission.shape[0], sample_submission.shape[1]))\n",
    "    return train, test, train_labels, specs, sample_submission\n",
    "\n",
    "def encode_title(train, test, train_labels):\n",
    "    # encode title\n",
    "    train['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), train['title'], train['event_code']))\n",
    "    test['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), test['title'], test['event_code']))\n",
    "    all_title_event_code = list(set(train[\"title_event_code\"].unique()).union(test[\"title_event_code\"].unique()))\n",
    "    # make a list with all the unique 'titles' from the train and test set\n",
    "    list_of_user_activities = list(set(train['title'].unique()).union(set(test['title'].unique())))\n",
    "    # make a list with all the unique 'event_code' from the train and test set\n",
    "    list_of_event_code = list(set(train['event_code'].unique()).union(set(test['event_code'].unique())))\n",
    "    list_of_event_id = list(set(train['event_id'].unique()).union(set(test['event_id'].unique())))\n",
    "    # make a list with all the unique worlds from the train and test set\n",
    "    list_of_worlds = list(set(train['world'].unique()).union(set(test['world'].unique())))\n",
    "    # create a dictionary numerating the titles\n",
    "    activities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n",
    "    activities_labels = dict(zip(np.arange(len(list_of_user_activities)), list_of_user_activities))\n",
    "    activities_world = dict(zip(list_of_worlds, np.arange(len(list_of_worlds))))\n",
    "    assess_titles = list(set(train[train['type'] == 'Assessment']['title'].value_counts().index).union(set(test[test['type'] == 'Assessment']['title'].value_counts().index)))\n",
    "    # replace the text titles with the number titles from the dict\n",
    "    train['title'] = train['title'].map(activities_map)\n",
    "    test['title'] = test['title'].map(activities_map)\n",
    "    train['world'] = train['world'].map(activities_world)\n",
    "    test['world'] = test['world'].map(activities_world)\n",
    "    train_labels['title'] = train_labels['title'].map(activities_map)\n",
    "    win_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\n",
    "    # then, it set one element, the 'Bird Measurer (Assessment)' as 4110, 10 more than the rest\n",
    "    win_code[activities_map['Bird Measurer (Assessment)']] = 4110\n",
    "    # convert text into datetime\n",
    "    train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "    test['timestamp'] = pd.to_datetime(test['timestamp'])\n",
    "    \n",
    "    \n",
    "    return train, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code\n",
    "\n",
    "\n",
    "# read data\n",
    "train, test, train_labels, specs, sample_submission = read_data()\n",
    "# get usefull dict with maping encode\n",
    "train, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code = encode_title(train, test, train_labels)\n",
    "# tranform function to get the train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_test(train, test):\n",
    "    compiled_train = []\n",
    "    compiled_test = []\n",
    "    compiled_val=[]\n",
    "    for i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort = False)), total = 17000):\n",
    "        compiled_train += get_data(user_sample)\n",
    "    for ins_id, user_sample in tqdm(test.groupby('installation_id', sort = False), total = 1000):\n",
    "        test_data,val_data = get_data(user_sample, test_set = True)\n",
    "        compiled_test.append(test_data)\n",
    "        compiled_val+=(val_data)\n",
    "    reduce_train = pd.DataFrame(compiled_train)\n",
    "    reduce_test = pd.DataFrame(compiled_test)\n",
    "    reduce_val = pd.DataFrame(compiled_val)\n",
    "    categoricals = ['session_title']\n",
    "    return reduce_train, reduce_test,reduce_val\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# import catboost as cat\n",
    "import time\n",
    "from collections import Counter\n",
    "import datetime\n",
    "# from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit, RepeatedStratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import linear_model\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# from bayes_opt import BayesianOptimization\n",
    "# import eli5\n",
    "# import shap\n",
    "# from IPython.display import HTML\n",
    "# import json\n",
    "# import altair as alt\n",
    "# from category_encoders.ordinal import OrdinalEncoder\n",
    "# import networkx as nx\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# from typing import List\n",
    "\n",
    "# import os\n",
    "# import time\n",
    "# import datetime\n",
    "# import json\n",
    "# import gc\n",
    "# from numba import jit\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# import lightgbm as lgb\n",
    "# import xgboost as xgb\n",
    "# from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "# from sklearn import metrics\n",
    "# from typing import Any\n",
    "# from itertools import product\n",
    "# pd.set_option('max_rows', 500)\n",
    "# import re\n",
    "# from tqdm import tqdm\n",
    "# from joblib import Parallel, delayed\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "pd.options.display.precision = 15\n",
    "from collections import defaultdict\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "def get_data(user_sample, test_set=False):\n",
    "    '''\n",
    "    The user_sample is a DataFrame from train or test where the only one \n",
    "    installation_id is filtered\n",
    "    And the test_set parameter is related with the labels processing, that is only requered\n",
    "    if test_set=False\n",
    "    '''\n",
    "    all_assessments=[]\n",
    "    # Constants and parameters declaration\n",
    "    event_code_count: Dict[str, int] = {ev: 0 for ev in list_of_event_code}\n",
    "    event_id_count: Dict[str, int] = {eve: 0 for eve in list_of_event_id}\n",
    "    title_count: Dict[str, int] = {eve: 0 for eve in activities_labels.values()} \n",
    "    title_event_code_count: Dict[str, int] = {t_eve: 0 for t_eve in all_title_event_code}\n",
    "    \n",
    "    \n",
    "    \n",
    "    ass_try_non_rec=0\n",
    "    ass_true_non_rec=0\n",
    "    ass_false_non_rec=0\n",
    "\n",
    "\n",
    "    ass_try_rec=0\n",
    "    ass_true_rec=0\n",
    "    ass_false_rec=0\n",
    "  \n",
    "  \n",
    "    try_non_rec=0\n",
    "    true_non_rec=0\n",
    "    false_non_rec=0\n",
    "\n",
    "    cnt=0\n",
    "    try_rec=0\n",
    "    true_rec=0\n",
    "    false_rec=0\n",
    "    cum_acc=0\n",
    "    # itarates through each session of one instalation_id\n",
    "    for i, session in user_sample.groupby('game_session', sort=False):\n",
    "        # i = game_session_id\n",
    "        # session is a DataFrame that contain only one game_session\n",
    "        \n",
    "        # get some sessions information\n",
    "        session_type = session['type'].iloc[0]\n",
    "        session_title = session['title'].iloc[0]\n",
    "        session_title_text = activities_labels[session_title]\n",
    "                    \n",
    "        rec=session.loc[session['event_code'].isin([4100,4110])]\n",
    "        non_rec=session.loc[~(session['event_code'].isin([4100,4110]))]\n",
    "        # for each assessment, and only this kind off session, the features below are processed\n",
    "        # and a register are generated\n",
    "        if (session_type == 'Assessment') & (test_set or len(session)>1):\n",
    "            features={}\n",
    "            # search for event_code 4100, that represents the assessments trial\n",
    "            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n",
    "            # then, check the numbers of wins and the number of losses\n",
    "            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n",
    "            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n",
    "            # copy a dict to use as feature template, it's initialized with some itens: \n",
    "            # {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "            features.update(event_code_count.copy())\n",
    "            features.update(event_id_count.copy())\n",
    "            features.update(title_count.copy())\n",
    "            features.update(title_event_code_count.copy())\n",
    "            features['true_rec_ass']=ass_true_rec\n",
    "            features['false_rec_ass']=ass_false_rec\n",
    "            features['tot_rec_ass']=ass_try_rec\n",
    "    \n",
    "      \n",
    "            features['true_non_rec_ass']=ass_true_non_rec\n",
    "            features['false_non_rec_ass']=ass_false_non_rec\n",
    "            features['tot_non_rec_ass']=ass_try_non_rec\n",
    "    \n",
    "      \n",
    "            features['true_rec_non_ass']=true_rec\n",
    "            features['false_rec_non_ass']=false_rec\n",
    "            features['tot_rec_non_ass']=try_rec\n",
    "    \n",
    "      \n",
    "            features['true_non_rec']=true_non_rec\n",
    "            features['false_non_rec']=false_non_rec\n",
    "            features['tot_non_rec']=try_non_rec\n",
    "            if cnt!=0:\n",
    "                features['accuracy_cum']=cum_acc/cnt\n",
    "            else:\n",
    "                features['accuracy_cum']=0\n",
    "            cnt+=1\n",
    "            # get installation_id for aggregated features\n",
    "            features['installation_id'] = session['installation_id'].iloc[-1]\n",
    "            # add title as feature, remembering that title represents the name of the game\n",
    "            features['session_title'] = session['title'].iloc[0]\n",
    "            # the 4 lines below add the feature of the history of the trials of this player\n",
    "            # this is based on the all time attempts so far, at the moment of this assessment\n",
    "            \n",
    "            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "            cum_acc+=accuracy\n",
    "            # a feature of the current accuracy categorized\n",
    "            # it is a counter of how many times this player was in each accuracy group\n",
    "            if accuracy == 0:\n",
    "                features['accuracy_group'] = 0\n",
    "            elif accuracy == 1:\n",
    "                features['accuracy_group'] = 3\n",
    "            elif accuracy == 0.5:\n",
    "                features['accuracy_group'] = 2\n",
    "            else:\n",
    "                features['accuracy_group'] = 1\n",
    "            # mean of the all accuracy groups of this player\n",
    "            true=rec.event_data.str.contains('true').sum()\n",
    "            false=rec.event_data.str.contains('false').sum()\n",
    "            tot=true+false\n",
    "        \n",
    "            # there are some conditions to allow this features to be inserted in the datasets\n",
    "            # if it's a test set, all sessions belong to the final dataset\n",
    "            # it it's a train, needs to be passed throught this clausule: session.query(f'event_code == {win_code[session_title]}')\n",
    "            # that means, must exist an event_code 4100 or 4110\n",
    "            if test_set:\n",
    "                all_assessments.append(features)\n",
    "            elif true_attempts+false_attempts > 0:\n",
    "                \n",
    "                #rec ass\n",
    "                ass_true_rec+=true\n",
    "                ass_false_rec+=false\n",
    "                ass_try_rec=ass_false_rec+ass_true_rec\n",
    "                \n",
    "                \n",
    "                all_assessments.append(features)\n",
    "      \n",
    "            else:\n",
    "            #non rec ass\n",
    "                ass_true_non_rec+=non_rec.event_data.str.contains('true').sum()\n",
    "                ass_false_non_rec+=non_rec.event_data.str.contains('false').sum()\n",
    "                ass_tot_non_rec=ass_true_non_rec+ass_false_non_rec\n",
    "      \n",
    "    \n",
    "    \n",
    "            \n",
    "        \n",
    "        # this piece counts how many actions was made in each event_code so far\n",
    "        def update_counters(counter: dict, col: str):\n",
    "                num_of_session_count = Counter(session[col])\n",
    "                for k in num_of_session_count.keys():\n",
    "                    x = k\n",
    "                    if col == 'title':\n",
    "                        x = activities_labels[k]\n",
    "                    counter[x] += num_of_session_count[k]\n",
    "                return counter\n",
    "            \n",
    "        event_code_count = update_counters(event_code_count, \"event_code\")\n",
    "        event_id_count = update_counters(event_id_count, \"event_id\")\n",
    "        title_count = update_counters(title_count, 'title')\n",
    "        title_event_code_count = update_counters(title_event_code_count, 'title_event_code')\n",
    "    \n",
    "        #non rec\n",
    "        true_non_rec+=(non_rec['event_data'].str.contains('true')).sum()\n",
    "        false_non_rec+=(non_rec['event_data'].str.contains('false')).sum()\n",
    "        tot_non_rec=true_non_rec+false_non_rec\n",
    "        #rec\n",
    "        true_rec+=(rec['event_data'].str.contains('true')).sum()\n",
    "        false_rec+=(rec['event_data'].str.contains('false')).sum()\n",
    "        tot_rec=false_rec+true_rec\n",
    "        # counts how many actions the player has done so far, used in the feature of the same name\n",
    "                        \n",
    "    # if it't the test_set, only the last assessment must be predicted, the previous are scraped\n",
    "    if test_set:\n",
    "        return all_assessments[-1],all_assessments[:-1]\n",
    "    # in the train_set, all assessments goes to the dataset\n",
    "    return all_assessments\n",
    "reduce_train, reduce_test, reduce_val= get_train_and_test(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "# for df in [reduce_train,reduce_test,reduce_val]:\n",
    "#     df=df\n",
    "trn_ft=lgb.Dataset(reduce_train.select_dtypes(exclude=object).drop(['accuracy_group'],1),reduce_train['accuracy_group'])\n",
    "val_ft=lgb.Dataset(reduce_val.select_dtypes(exclude=object).drop(['accuracy_group'],1),reduce_val['accuracy_group'])\n",
    "mod=lgb.train( {'feature_fraction': 0.7975023410800904,'n_estimators':7297,'learning_rate':0.001,\n",
    "  'max_depth': 14,\n",
    "  'subsample': 0.7531064105216918},trn_ft)\n",
    "pre=mod.predict(reduce_test.select_dtypes(exclude=object).drop(['accuracy_group'],1))\n",
    "x,y,z=1.21519937, 1.70523477, 2.25945307\n",
    "res=[]\n",
    "for i in pre:\n",
    "        if i<x:\n",
    "            res.append(0)\n",
    "        elif i<y:\n",
    "            res.append(1)\n",
    "        elif i<z:\n",
    "            res.append(2)\n",
    "        else:\n",
    "            res.append(3)\n",
    "\n",
    "\n",
    "sample_submission['accuracy_group']=res\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission['accuracy_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
