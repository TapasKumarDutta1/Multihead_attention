{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled22.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMURH6/Rm+VcobtcxBJC8u5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/Data_Science_bowl-2019/blob/master/DSB-2019.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRhdanI3hITF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "23b78d3f-07aa-4c5b-d02c-9aeb2cfc0059"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"\" # key from the json file\n",
        "!kaggle competitions download -c data-science-bowl-2019"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading test.csv.zip to /content\n",
            " 98% 40.0M/40.8M [00:00<00:00, 52.2MB/s]\n",
            "100% 40.8M/40.8M [00:00<00:00, 92.1MB/s]\n",
            "Downloading specs.csv to /content\n",
            "  0% 0.00/399k [00:00<?, ?B/s]\n",
            "100% 399k/399k [00:00<00:00, 125MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/10.8k [00:00<?, ?B/s]\n",
            "100% 10.8k/10.8k [00:00<00:00, 11.4MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            "100% 397M/397M [00:03<00:00, 151MB/s]\n",
            "\n",
            "Downloading train_labels.csv.zip to /content\n",
            "  0% 0.00/262k [00:00<?, ?B/s]\n",
            "100% 262k/262k [00:00<00:00, 83.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hUo5z-lhXaX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bb3d91e4-5be3-408b-a5e5-f80971d3823d"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "def read_data():\n",
        "    train = pd.read_csv('train.csv.zip',nrows=100000)\n",
        "    \n",
        "    test = pd.read_csv('test.csv.zip')\n",
        "    \n",
        "    train_labels = pd.read_csv('train_labels.csv.zip',nrows=100000)\n",
        "    \n",
        "    specs = pd.read_csv('specs.csv',nrows=100000)\n",
        "\n",
        "    sample_submission = pd.read_csv('sample_submission.csv',nrows=100000)\n",
        "    return train, test, train_labels, specs, sample_submission\n",
        "\n",
        "def encode_title(train, test, train_labels):\n",
        "    # encode title\n",
        "    train['title_event_code'] = train['title'].astype(str)+train['event_code'].astype(str)\n",
        "    test['title_event_code'] = test['title'].astype(str)+test['event_code'].astype(str)\n",
        "    \n",
        "    titles = list(set(train['title'].unique()).union(set(test['title'].unique())))\n",
        "    event_code = list(set(train['event_code'].unique()).union(set(test['event_code'].unique())))\n",
        "    event_id = list(set(train['event_id'].unique()).union(set(test['event_id'].unique())))\n",
        "    worlds = list(set(train['world'].unique()).union(set(test['world'].unique())))\n",
        "    title_code = list(set(train['title_event_code'].unique()).union(set(test['title_event_code'].unique())))\n",
        "    \n",
        "    \n",
        "    \n",
        "    event_code_map = dict(zip(event_code, np.arange(len(event_code))))\n",
        "    \n",
        "    title_map = dict(zip(titles, np.arange(len(titles))))\n",
        "    title_demap = dict(zip(np.arange(len(titles)),titles ))\n",
        "    \n",
        "    event_id_map = dict(zip(event_id,np.arange(len(event_id))))\n",
        "    world_map = dict(zip(worlds, np.arange(len(worlds))))\n",
        "    \n",
        "    title_code_map=dict(zip(title_code,np.arange(len(title_code))))\n",
        "    title_code_demap=dict(zip(np.arange(len(title_code)),title_code))\n",
        "    \n",
        "    \n",
        "    # replace the text titles with the number titles from the dict\n",
        "    train['title'] = train['title'].map(title_map)\n",
        "    test['title'] = test['title'].map(title_map)\n",
        "    train['world'] = train['world'].map(world_map)\n",
        "    test['world'] = test['world'].map(world_map)\n",
        "    train_labels['title'] = train_labels['title'].map(title_map)\n",
        "    \n",
        "    train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
        "    test['timestamp'] = pd.to_datetime(test['timestamp'])\n",
        "    \n",
        "    \n",
        "    win_code={col:4100 for col in train.loc[train['type']=='Assessment']['title'].unique()}\n",
        "    win_code[title_map['Bird Measurer (Assessment)']]=4110\n",
        "    \n",
        "    return train, test, train_labels, title_map,title_demap,world_map,title_code,win_code,event_code_map,event_id_map\n",
        "\n",
        "train, test, train_labels, specs, sample_submission = read_data()\n",
        "train, test, train_labels, title_map,title_demap,world_map,title_code,win_code,event_code_map,event_id_map = encode_title(train, test, train_labels)\n",
        "\n",
        "def get_train_and_test(train, test):\n",
        "    compiled_train = []\n",
        "    compiled_test = []\n",
        "    compiled_val=[]\n",
        "    for i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort = False))):\n",
        "        compiled_train += get_data(user_sample)\n",
        "    for ins_id, user_sample in tqdm(test.groupby('installation_id', sort = False)):\n",
        "        test_data,val_data = get_data(user_sample, test_set = True)\n",
        "        compiled_test.append(test_data)\n",
        "        compiled_val+=(val_data)\n",
        "    reduce_train = pd.DataFrame(compiled_train)\n",
        "    reduce_test = pd.DataFrame(compiled_test)\n",
        "    reduce_val = pd.DataFrame(compiled_val)\n",
        "    categoricals = ['session_title']\n",
        "    return reduce_train, reduce_test,reduce_val\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import time\n",
        "from collections import Counter\n",
        "import datetime\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit, RepeatedStratifiedKFold\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn import linear_model\n",
        "import gc\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from tqdm import tqdm_notebook\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import NuSVR, SVR\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "pd.options.display.precision = 15\n",
        "from collections import defaultdict\n",
        "import lightgbm as lgb\n",
        "\n",
        "def get_data(user_sample, test_set=False):\n",
        "    all_assessments=[]\n",
        "    event_code_count: Dict[str, int] = {ev: 0 for ev in list(event_code_map.keys())}\n",
        "    event_id_count: Dict[str, int] = {eve: 0 for eve in list(event_id_map.keys())}\n",
        "    title_count: Dict[str, int] = {eve: 0 for eve in list(title_map.keys())} \n",
        "    title_code_count: Dict[str, int] = {t_eve: 0 for t_eve in title_code}\n",
        "    \n",
        "    \n",
        "    \n",
        "    ass_try_non_rec=0\n",
        "    ass_true_non_rec=0\n",
        "    ass_false_non_rec=0\n",
        "\n",
        "\n",
        "    ass_try_rec=0\n",
        "    ass_true_rec=0\n",
        "    ass_false_rec=0\n",
        "  \n",
        "  \n",
        "    try_non_rec=0\n",
        "    true_non_rec=0\n",
        "    false_non_rec=0\n",
        "\n",
        "    cnt=0\n",
        "    try_rec=0\n",
        "    true_rec=0\n",
        "    false_rec=0\n",
        "    cum_acc=0\n",
        "    for i, session in user_sample.groupby('game_session', sort=False):\n",
        "        \n",
        "        session_type = session['type'].iloc[0]\n",
        "        session_title = session['title'].iloc[0]\n",
        "        session_title_text = title_demap[session_title]\n",
        "                    \n",
        "        rec=session.loc[session['event_code'].isin([4100,4110])]\n",
        "        non_rec=session.loc[~(session['event_code'].isin([4100,4110]))]\n",
        "        \n",
        "        if (session_type == 'Assessment') & (test_set or len(session)>1):\n",
        "            features={}\n",
        "            all_attempts = session.loc[session['event_code']==win_code[session_title]]\n",
        "            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n",
        "            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n",
        "            features.update(event_code_count.copy())\n",
        "            features.update(event_id_count.copy())\n",
        "            features.update(title_count.copy())\n",
        "            features.update(title_code_count.copy())\n",
        "            \n",
        "            \n",
        "            #recorded_assessments\n",
        "            features['true_rec_ass']=ass_true_rec\n",
        "            features['false_rec_ass']=ass_false_rec\n",
        "            features['tot_rec_ass']=ass_try_rec\n",
        "    \n",
        "            #non_recorded assessmnents\n",
        "            features['true_non_rec_ass']=ass_true_non_rec\n",
        "            features['false_non_rec_ass']=ass_false_non_rec\n",
        "            features['tot_non_rec_ass']=ass_try_non_rec\n",
        "    \n",
        "            #all recorded\n",
        "            features['true_rec_non_ass']=true_rec\n",
        "            features['false_rec_non_ass']=false_rec\n",
        "            features['tot_rec_non_ass']=try_rec\n",
        "    \n",
        "            #all non recorded\n",
        "            features['true_non_rec']=true_non_rec\n",
        "            features['false_non_rec']=false_non_rec\n",
        "            features['tot_non_rec']=try_non_rec\n",
        "            if cnt!=0:\n",
        "                features['accuracy_cum']=cum_acc/cnt\n",
        "            else:\n",
        "                features['accuracy_cum']=0\n",
        "            cnt+=1\n",
        "            features['installation_id'] = session['installation_id'].iloc[-1]\n",
        "            features['session_title'] = session['title'].iloc[0]\n",
        "            \n",
        "            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
        "            cum_acc+=accuracy\n",
        "            if accuracy == 0:\n",
        "                features['accuracy_group'] = 0\n",
        "            elif accuracy == 1:\n",
        "                features['accuracy_group'] = 3\n",
        "            elif accuracy == 0.5:\n",
        "                features['accuracy_group'] = 2\n",
        "            else:\n",
        "                features['accuracy_group'] = 1\n",
        "            true=rec.event_data.str.contains('true').sum()\n",
        "            false=rec.event_data.str.contains('false').sum()\n",
        "            tot=true+false\n",
        "        \n",
        "            if test_set:\n",
        "                all_assessments.append(features)\n",
        "            elif true_attempts+false_attempts > 0:\n",
        "                \n",
        "                ass_true_rec+=true\n",
        "                ass_false_rec+=false\n",
        "                ass_try_rec=ass_false_rec+ass_true_rec\n",
        "                \n",
        "                \n",
        "                all_assessments.append(features)\n",
        "      \n",
        "            else:\n",
        "            #non rec ass\n",
        "                ass_true_non_rec+=non_rec.event_data.str.contains('true').sum()\n",
        "                ass_false_non_rec+=non_rec.event_data.str.contains('false').sum()\n",
        "                ass_tot_non_rec=ass_true_non_rec+ass_false_non_rec\n",
        "      \n",
        "    \n",
        "    \n",
        "            \n",
        "        \n",
        "        # this piece counts how many actions was made in each event_code so far\n",
        "        def update_counters(counter: dict, col: str):\n",
        "                num_of_session_count = Counter(session[col])\n",
        "                for k in num_of_session_count.keys():\n",
        "                    x = k\n",
        "                    if col == 'title':\n",
        "                        x = title_demap[k]\n",
        "                    counter[x] += num_of_session_count[k]\n",
        "                return counter\n",
        "            \n",
        "        event_code_count = update_counters(event_code_count, \"event_code\")\n",
        "        event_id_count = update_counters(event_id_count, \"event_id\")\n",
        "        title_count = update_counters(title_count, 'title')\n",
        "        title_code_count = update_counters(title_code_count, 'title_event_code')\n",
        "    \n",
        "        #non rec\n",
        "        true_non_rec+=(non_rec['event_data'].str.contains('true')).sum()\n",
        "        false_non_rec+=(non_rec['event_data'].str.contains('false')).sum()\n",
        "        tot_non_rec=true_non_rec+false_non_rec\n",
        "        #rec\n",
        "        true_rec+=(rec['event_data'].str.contains('true')).sum()\n",
        "        false_rec+=(rec['event_data'].str.contains('false')).sum()\n",
        "        tot_rec=false_rec+true_rec\n",
        "        # counts how many actions the player has done so far, used in the feature of the same name\n",
        "                        \n",
        "    # if it't the test_set, only the last assessment must be predicted, the previous are scraped\n",
        "    if test_set:\n",
        "        return all_assessments[-1],all_assessments[:-1]\n",
        "    # in the train_set, all assessments goes to the dataset\n",
        "    return all_assessments\n",
        "reduce_train, reduce_test, reduce_val= get_train_and_test(train, test)\n",
        "reduce_test.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in reduce_test.columns]\n",
        "reduce_train.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in reduce_train.columns]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157it [00:11, 13.44it/s]\n",
            "100%|██████████| 1000/1000 [01:57<00:00,  8.48it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nwJbxHIhfDD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "7f74e970-5943-45ee-ba11-8919f5cdf46e"
      },
      "source": [
        "\n",
        "trn_ft=lgb.Dataset(reduce_train.select_dtypes(exclude=object).drop(['accuracy_group'],1),reduce_train['accuracy_group'])\n",
        "val_ft=lgb.Dataset(reduce_val.select_dtypes(exclude=object).drop(['accuracy_group'],1),reduce_val['accuracy_group'])\n",
        "mod=lgb.train( {'feature_fraction': 0.7975023410800904,'n_estimators':7297,'learning_rate':0.001,\n",
        "  'max_depth': 14,\n",
        "  'subsample': 0.7531064105216918},trn_ft)\n",
        "pre=mod.predict(reduce_test.select_dtypes(exclude=object).drop(['accuracy_group'],1))\n",
        "x,y,z=1.21519937, 1.70523477, 2.25945307\n",
        "res=[]\n",
        "for i in pre:\n",
        "        if i<x:\n",
        "            res.append(0)\n",
        "        elif i<y:\n",
        "            res.append(1)\n",
        "        elif i<z:\n",
        "            res.append(2)\n",
        "        else:\n",
        "            res.append(3)\n",
        "\n",
        "\n",
        "sample_submission['accuracy_group']=res\n",
        "sample_submission.to_csv('submission.csv', index=False)\n",
        "sample_submission['accuracy_group'].value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    447\n",
              "2    198\n",
              "0    192\n",
              "1    163\n",
              "Name: accuracy_group, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tND8qB_ixVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}