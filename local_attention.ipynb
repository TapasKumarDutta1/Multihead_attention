{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "local_attention.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM5vL6GhDEypuIb3cNGY0u1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/Multihead_attention/blob/master/local_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15sDLraDJWlh"
      },
      "source": [
        "class Attention(Layer):\r\n",
        "    \r\n",
        "    def __init__(self, context='many-to-many', alignment_type='global', window_width=None,\r\n",
        "                 score_function='general', model_api='functional', **kwargs):\r\n",
        "        if context not in ['many-to-many', 'many-to-one']:\r\n",
        "            raise ValueError(\"Argument for param @context is not recognized\")\r\n",
        "        if alignment_type not in ['global', 'local-m', 'local-p', 'local-p*']:\r\n",
        "            raise ValueError(\"Argument for param @alignment_type is not recognized\")\r\n",
        "        if alignment_type == 'global' and window_width is not None:\r\n",
        "            raise ValueError(\"Can't use windowed approach with global attention\")\r\n",
        "        if context == 'many-to-many' and alignment_type == 'local-p*':\r\n",
        "            raise ValueError(\"Can't use local-p* approach in many-to-many scenarios\")\r\n",
        "        if score_function not in ['dot', 'general', 'location', 'concat', 'scaled_dot']:\r\n",
        "            raise ValueError(\"Argument for param @score_function is not recognized\")\r\n",
        "        if model_api not in ['sequential', 'functional']:\r\n",
        "            raise ValueError(\"Argument for param @model_api is not recognized\")\r\n",
        "        super(Attention, self).__init__(**kwargs)\r\n",
        "        self.context = context\r\n",
        "        self.alignment_type = alignment_type\r\n",
        "        self.window_width = window_width  # D\r\n",
        "        self.score_function = score_function\r\n",
        "        self.model_api = model_api\r\n",
        "\r\n",
        "    def get_config(self):\r\n",
        "        base_config = super(Attention, self).get_config()\r\n",
        "        base_config['alignment_type'] = self.alignment_type\r\n",
        "        base_config['window_width'] = self.window_width\r\n",
        "        base_config['score_function'] = self.score_function\r\n",
        "        base_config['model_api'] = self.model_api\r\n",
        "        return base_config\r\n",
        "\r\n",
        "    def build(self, input_shape):\r\n",
        "        # Declare attributes for easy access to dimension values\r\n",
        "        if self.context == 'many-to-many':\r\n",
        "            self.input_sequence_length, self.hidden_dim = input_shape[0][1], input_shape[0][2]\r\n",
        "            self.target_sequence_length = input_shape[1][1]\r\n",
        "        elif self.context == 'many-to-one':\r\n",
        "            self.input_sequence_length, self.hidden_dim = input_shape[0][1], input_shape[0][2]\r\n",
        "\r\n",
        "        # Build weight matrices for different alignment types and score functions\r\n",
        "        if 'local-p' in self.alignment_type:\r\n",
        "            self.W_p = Dense(units=self.hidden_dim, use_bias=False)\r\n",
        "            self.W_p.build(input_shape=(None, None, self.hidden_dim))                               # (B, 1, H)\r\n",
        "            self._trainable_weights += self.W_p.trainable_weights\r\n",
        "\r\n",
        "            self.v_p = Dense(units=1, use_bias=False)\r\n",
        "            self.v_p.build(input_shape=(None, None, self.hidden_dim))                               # (B, 1, H)\r\n",
        "            self._trainable_weights += self.v_p.trainable_weights\r\n",
        "\r\n",
        "        if 'dot' not in self.score_function:  # weight matrix not utilized for 'dot' function\r\n",
        "            self.W_a = Dense(units=self.hidden_dim, use_bias=False)\r\n",
        "            self.W_a.build(input_shape=(None, None, self.hidden_dim))                               # (B, S*, H)\r\n",
        "            self._trainable_weights += self.W_a.trainable_weights\r\n",
        "\r\n",
        "        if self.score_function == 'concat':  # define additional weight matrices\r\n",
        "            self.U_a = Dense(units=self.hidden_dim, use_bias=False)\r\n",
        "            self.U_a.build(input_shape=(None, None, self.hidden_dim))                               # (B, 1, H)\r\n",
        "            self._trainable_weights += self.U_a.trainable_weights\r\n",
        "\r\n",
        "            self.v_a = Dense(units=1, use_bias=False)\r\n",
        "            self.v_a.build(input_shape=(None, None, self.hidden_dim))                               # (B, S*, H)\r\n",
        "            self._trainable_weights += self.v_a.trainable_weights\r\n",
        "\r\n",
        "        super(Attention, self).build(input_shape)\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        # Pass decoder output (prev. timestep) alongside encoder output for all scenarios\r\n",
        "        if not isinstance(inputs, list):\r\n",
        "            raise ValueError(\"Pass a list=[encoder_out (Tensor), decoder_out (Tensor),\" +\r\n",
        "                             \"current_timestep (int)] for all scenarios\")\r\n",
        "\r\n",
        "        target_hidden_state = inputs[1]                                                         # (B, H)\r\n",
        "        current_timestep = inputs[2]\r\n",
        "        source_hidden_states = inputs[0]                                                        # (B, S, H)\r\n",
        "\r\n",
        "        target_hidden_state = tf.expand_dims(input=target_hidden_state, axis=1)                     # (B, 1, H)\r\n",
        "\r\n",
        "        self.window_width = 8 if self.window_width is None else self.window_width\r\n",
        "        aligned_position = self.W_p(target_hidden_state)                                    # (B, 1, H)\r\n",
        "        aligned_position = Activation('tanh')(aligned_position)                             # (B, 1, H)\r\n",
        "        aligned_position = self.v_p(aligned_position)                                       # (B, 1, 1)\r\n",
        "        aligned_position = Activation('sigmoid')(aligned_position)                          # (B, 1, 1)\r\n",
        "        aligned_position = aligned_position * self.input_sequence_length                    # (B, 1, 1)\r\n",
        "\r\n",
        "        attention_score = Dot(axes=[2, 2])([source_hidden_states, target_hidden_state])         # (B, S*, 1)\r\n",
        "        if self.score_function == 'scaled_dot':\r\n",
        "                attention_score *= 1 / np.sqrt(float(source_hidden_states.shape[2]))                # (B, S*, 1)\r\n",
        "\r\n",
        "        attention_weights = Activation('softmax')(attention_score)                                  # (B, S*, 1)\r\n",
        "\r\n",
        "        gaussian_estimation = lambda s: tf.exp(-tf.square(s - aligned_position) /\r\n",
        "                                                   (2 * tf.square(self.window_width / 2)))\r\n",
        "        gaussian_factor = gaussian_estimation(0)\r\n",
        "        for i in range(1, self.input_sequence_length):\r\n",
        "                gaussian_factor = Concatenate(axis=1)([gaussian_factor, gaussian_estimation(i)])    # (B, S*, 1)\r\n",
        "        attention_weights = attention_weights * gaussian_factor                                 # (B, S*, 1)\r\n",
        "\r\n",
        "        context_vector = source_hidden_states * attention_weights                                   # (B, S*, H)\r\n",
        "\r\n",
        "        if self.model_api == 'functional':\r\n",
        "            return context_vector, attention_weights\r\n",
        "        elif self.model_api == 'sequential':\r\n",
        "            return context_vector"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}