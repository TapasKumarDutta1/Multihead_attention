{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "gated_5_6514_spatial_adadelta.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/Multihead_attention/blob/master/gated_5_6514_spatial_adadelta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQqlrXIJej1l",
        "outputId": "f560ee04-6747-4e2e-aeae-8fae5b6ecc1d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WXDyhihenRg"
      },
      "source": [
        "import zipfile\n",
        "import h5py\n",
        "from tensorflow.keras.optimizers import *\n",
        "import cv2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import glob, os\n",
        "from matplotlib import pyplot as plt\n",
        "import h5py\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import gc\n",
        "from tensorflow.keras.applications import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ_0F8Zfep7F"
      },
      "source": [
        "path = F\"/content/gdrive/My Drive/check.npy\" \n",
        "df=np.load(path,allow_pickle=True)\n",
        "df=df.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OauHZNZMerDG"
      },
      "source": [
        "\n",
        "#shuffle samples\n",
        "def unison_shuffled_copies(a, b):\n",
        "    assert len(a) == len(b)\n",
        "    p = np.random.permutation(len(a))\n",
        "    return a[p], b[p]\n",
        "\n",
        "\n",
        "\n",
        "#change targets\n",
        "def change(img):\n",
        "    resized = cv2.resize(img, (224,224), interpolation = cv2.INTER_AREA )\n",
        "    return resized\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#get train and test splits\n",
        "def get_trn_tst(df,tst_fold):\n",
        "  idx=np.asarray(df['fold'])\n",
        "  y=np.asarray(df['label'])\n",
        "  y-=1\n",
        "  img=np.asarray(df['image'])\n",
        "  img1=[]\n",
        "  for i in range(len(img)):\n",
        "        img1.append(change(img[i]))\n",
        "  img1=np.asarray(img1)\n",
        "  del([img])\n",
        "  gc.collect()\n",
        "  trn_y=np.asarray(y[(idx!=tst_fold)])\n",
        "  trn_img=np.asarray(img1[(idx!=tst_fold)])\n",
        "  tst_y=np.asarray(y[(idx==tst_fold)])\n",
        "  tst_img=img1[idx==tst_fold]\n",
        "  trn_img=np.repeat(trn_img.reshape((trn_img.shape[0],224,224,1)),3,axis=3)\n",
        "  tst_img=np.repeat(tst_img.reshape((tst_img.shape[0],224,224,1)),3,axis=3)\n",
        "  return (trn_img.copy(),trn_y.copy()),(tst_img.copy(),tst_y.copy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mja2yCpAINM4"
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import random, os, sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo9D7_Mt01Qq"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "class LayerNormalization(Layer):\n",
        "    def __init__(self, eps=1e-6, **kwargs):\n",
        "        self.eps = eps\n",
        "        super(LayerNormalization, self).__init__(**kwargs)\n",
        "    def build(self, input_shape):\n",
        "        self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:],\n",
        "                                     initializer=Ones(), trainable=True)\n",
        "        self.beta = self.add_weight(name='beta', shape=input_shape[-1:],\n",
        "                                    initializer=Zeros(), trainable=True)\n",
        "        super(LayerNormalization, self).build(input_shape)\n",
        "    def call(self, x):\n",
        "        mean = K.mean(x, axis=-1, keepdims=True)\n",
        "        std = K.std(x, axis=-1, keepdims=True)\n",
        "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "class abc(keras.layers.Layer):\n",
        "    def __init__(self,\n",
        "                 head_num,\n",
        "                 q_k,\n",
        "                 activation='relu',\n",
        "                 use_bias=True,\n",
        "                 kernel_initializer='glorot_normal',\n",
        "                 bias_initializer='zeros',\n",
        "                 kernel_regularizer=None,\n",
        "                 bias_regularizer=None,\n",
        "                 kernel_constraint=None,\n",
        "                 bias_constraint=None,\n",
        "                 history_only=False,\n",
        "                 **kwargs):\n",
        "        self.q_k=q_k\n",
        "        self.supports_masking = True\n",
        "        self.head_num = head_num\n",
        "        self.activation = keras.activations.get(activation)\n",
        "        self.use_bias = use_bias\n",
        "        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
        "        self.bias_initializer = keras.initializers.get(bias_initializer)\n",
        "        self.kernel_regularizer = keras.regularizers.get(kernel_regularizer)\n",
        "        self.bias_regularizer = keras.regularizers.get(bias_regularizer)\n",
        "        self.kernel_constraint = keras.constraints.get(kernel_constraint)\n",
        "        self.bias_constraint = keras.constraints.get(bias_constraint)\n",
        "        self.history_only = history_only\n",
        "\n",
        "        self.Wq = self.Wk = self.Wv = self.Wo = None\n",
        "        self.bq = self.bk = self.bv = self.bo = None\n",
        "\n",
        "        self.intensity = self.attention = None\n",
        "        super(abc, self).__init__(**kwargs)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'head_num': self.head_num,\n",
        "            'activation': keras.activations.serialize(self.activation),\n",
        "            'use_bias': self.use_bias,\n",
        "            'kernel_initializer': keras.initializers.serialize(self.kernel_initializer),\n",
        "            'bias_initializer': keras.initializers.serialize(self.bias_initializer),\n",
        "            'kernel_regularizer': keras.regularizers.serialize(self.kernel_regularizer),\n",
        "            'bias_regularizer': keras.regularizers.serialize(self.bias_regularizer),\n",
        "            'kernel_constraint': keras.constraints.serialize(self.kernel_constraint),\n",
        "            'bias_constraint': keras.constraints.serialize(self.bias_constraint),\n",
        "            'history_only': self.history_only,\n",
        "        }\n",
        "        base_config = super(abc, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if isinstance(input_shape, list):\n",
        "            q, k, v = input_shape\n",
        "            return q[:-1] + (v[-1],)\n",
        "        return input_shape\n",
        "\n",
        "    def compute_mask(self, inputs, input_mask=None):\n",
        "        if isinstance(input_mask, list):\n",
        "            return input_mask[0]\n",
        "        return input_mask\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.layer_norm = LayerNormalization()\n",
        "        if isinstance(input_shape, list):\n",
        "            q, k, v = input_shape\n",
        "        else:\n",
        "            q = k = v = input_shape\n",
        "        feature_dim = int(v[-1])\n",
        "        if feature_dim % self.head_num != 0:\n",
        "            raise IndexError('Invalid head number %d with the given input dim %d' % (self.head_num, feature_dim))\n",
        "        self.Wq = self.add_weight(\n",
        "            shape=(int(q[-1]), self.q_k),\n",
        "            initializer=self.kernel_initializer,\n",
        "            regularizer=self.kernel_regularizer,\n",
        "            constraint=self.kernel_constraint,\n",
        "            name='%s_Wq' % self.name,\n",
        "        )\n",
        "        if self.use_bias:\n",
        "            self.bq = self.add_weight(\n",
        "                shape=(self.q_k,),\n",
        "                initializer=self.bias_initializer,\n",
        "                regularizer=self.bias_regularizer,\n",
        "                constraint=self.bias_constraint,\n",
        "                name='%s_bq' % self.name,\n",
        "            )\n",
        "        self.Wk = self.add_weight(\n",
        "            shape=(int(k[-1]), self.q_k),\n",
        "            initializer=self.kernel_initializer,\n",
        "            regularizer=self.kernel_regularizer,\n",
        "            constraint=self.kernel_constraint,\n",
        "            name='%s_Wk' % self.name,\n",
        "        )\n",
        "        if self.use_bias:\n",
        "            self.bk = self.add_weight(\n",
        "                shape=(self.q_k,),\n",
        "                initializer=self.bias_initializer,\n",
        "                regularizer=self.bias_regularizer,\n",
        "                constraint=self.bias_constraint,\n",
        "                name='%s_bk' % self.name,\n",
        "            )\n",
        "        self.Wv = self.add_weight(\n",
        "            shape=(int(v[-1]), feature_dim),\n",
        "            initializer=self.kernel_initializer,\n",
        "            regularizer=self.kernel_regularizer,\n",
        "            constraint=self.kernel_constraint,\n",
        "            name='%s_Wv' % self.name,\n",
        "        )\n",
        "        if self.use_bias:\n",
        "            self.bv = self.add_weight(\n",
        "                shape=(feature_dim,),\n",
        "                initializer=self.bias_initializer,\n",
        "                regularizer=self.bias_regularizer,\n",
        "                constraint=self.bias_constraint,\n",
        "                name='%s_bv' % self.name,\n",
        "            )\n",
        "        self.Wo = self.add_weight(\n",
        "            shape=(feature_dim, feature_dim),\n",
        "            initializer=self.kernel_initializer,\n",
        "            regularizer=self.kernel_regularizer,\n",
        "            constraint=self.kernel_constraint,\n",
        "            name='%s_Wo' % self.name,\n",
        "        )\n",
        "        if self.use_bias:\n",
        "            self.bo = self.add_weight(\n",
        "                shape=(feature_dim,),\n",
        "                initializer=self.bias_initializer,\n",
        "                regularizer=self.bias_regularizer,\n",
        "                constraint=self.bias_constraint,\n",
        "                name='%s_bo' % self.name,\n",
        "            )\n",
        "        super(abc, self).build(input_shape)\n",
        "\n",
        "    @staticmethod\n",
        "    def _reshape_to_batches(x, head_num):\n",
        "        input_shape = K.shape(x)\n",
        "        batch_size, seq_len, feature_dim = input_shape[0], input_shape[1], input_shape[2]\n",
        "        head_dim = feature_dim // head_num\n",
        "        x = K.reshape(x, (batch_size, seq_len, head_num, head_dim))\n",
        "        x = K.permute_dimensions(x, [0, 2, 1, 3])\n",
        "        return K.reshape(x, (batch_size * head_num, seq_len, head_dim))\n",
        "\n",
        "    @staticmethod\n",
        "    def _reshape_attention_from_batches(x, head_num):\n",
        "        input_shape = K.shape(x)\n",
        "        batch_size, seq_len, feature_dim = input_shape[0], input_shape[1], input_shape[2]\n",
        "        x = K.reshape(x, (batch_size // head_num, head_num, seq_len, feature_dim))\n",
        "        return K.permute_dimensions(x, [0, 2, 1, 3])\n",
        "\n",
        "    @staticmethod\n",
        "    def _reshape_from_batches(x, head_num):\n",
        "        input_shape = K.shape(x)\n",
        "        batch_size, seq_len, feature_dim = input_shape[0], input_shape[1], input_shape[2]\n",
        "        x = K.reshape(x, (batch_size // head_num, head_num, seq_len, feature_dim))\n",
        "        x = K.permute_dimensions(x, [0, 2, 1, 3])\n",
        "        return K.reshape(x, (batch_size // head_num, seq_len, feature_dim * head_num))\n",
        "\n",
        "    @staticmethod\n",
        "    def _reshape_mask(mask, head_num):\n",
        "        if mask is None:\n",
        "            return mask\n",
        "        seq_len = K.shape(mask)[1]\n",
        "        mask = K.expand_dims(mask, axis=1)\n",
        "        mask = K.tile(mask, [1, head_num, 1])\n",
        "        return K.reshape(mask, (-1, seq_len))\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if isinstance(inputs, list):\n",
        "            q, k, v = inputs\n",
        "        else:\n",
        "            q = k = v = inputs\n",
        "        if isinstance(mask, list):\n",
        "            q_mask, k_mask, v_mask = mask\n",
        "        else:\n",
        "            q_mask = k_mask = v_mask = mask\n",
        "        q = K.dot(q, self.Wq)\n",
        "        k = K.dot(k, self.Wk)\n",
        "        v = K.dot(v, self.Wv)\n",
        "        if self.use_bias:\n",
        "            q += self.bq\n",
        "            k += self.bk\n",
        "            v += self.bv\n",
        "        if self.activation is not None:\n",
        "            q = self.activation(q)\n",
        "            k = self.activation(k)\n",
        "            v = self.activation(v)\n",
        "        def scaled_dot_product_attention(inputs):\n",
        "          query, key, value = inputs\n",
        "          feature_dim = K.shape(query)[-1]\n",
        "          e = K.batch_dot(query, key, axes=2) / K.sqrt(K.cast(self.q_k, dtype=K.floatx()))\n",
        "          intensity = e\n",
        "          e = K.exp(e - K.max(e, axis=-1, keepdims=True))\n",
        "          attention = e / K.sum(e, axis=-1, keepdims=True)\n",
        "          v = K.batch_dot(attention, value)\n",
        "          return v,intensity,attention\n",
        "       \n",
        "       \n",
        "        y,intensity,attention = scaled_dot_product_attention(\n",
        "            inputs=[\n",
        "                self._reshape_to_batches(q, self.head_num),\n",
        "                self._reshape_to_batches(k, self.head_num),\n",
        "                self._reshape_to_batches(v, self.head_num),\n",
        "            ]\n",
        "        )\n",
        "        self.intensity = self._reshape_attention_from_batches(intensity, self.head_num)\n",
        "        self.attention = self._reshape_attention_from_batches(attention, self.head_num)\n",
        "        y = self._reshape_from_batches(y, self.head_num)\n",
        "        y = K.dot(y, self.Wo)\n",
        "        if self.use_bias:\n",
        "            y += self.bo\n",
        "        if self.activation is not None:\n",
        "            y = self.activation(y)\n",
        "        return y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES4W36q1Kz7Y"
      },
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from keras.activations import softmax\n",
        "from tensorflow.keras import backend as K\n",
        "class LayerNormalization(Layer):\n",
        "    def __init__(self, eps=1e-6, **kwargs):\n",
        "        self.eps = eps\n",
        "        super(LayerNormalization, self).__init__(**kwargs)\n",
        "    def build(self, input_shape):\n",
        "        self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:],\n",
        "                                     initializer=Ones(), trainable=True)\n",
        "        self.beta = self.add_weight(name='beta', shape=input_shape[-1:],\n",
        "                                    initializer=Zeros(), trainable=True)\n",
        "        super(LayerNormalization, self).build(input_shape)\n",
        "    def call(self, x):\n",
        "        mean = K.mean(x, axis=-1, keepdims=True)\n",
        "        std = K.std(x, axis=-1, keepdims=True)\n",
        "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "class abc(Layer):\n",
        "    def __init__(self,inr,mo,up,**kwargs):\n",
        "        super(abc, self).__init__(**kwargs)\n",
        "        self.inr=inr\n",
        "        self.mo=mo\n",
        "        self.up=up\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super(abc, self).get_config()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(abc, self).build(input_shape)\n",
        "        self.cv1 = Conv2D(self.inr,1)\n",
        "        self.cv2 = Conv2D(self.inr,1)\n",
        "        self.cv3 = Conv2D(1,1)\n",
        "        self.up = UpSampling2D(interpolation='bilinear',size=(self.up,self.up))\n",
        "        self.dns1=Dense(1)\n",
        "    def call(self, img,y):\n",
        "        y = self.cv1(y)\n",
        "        y = self.up(y)\n",
        "        x = self.cv2(img)\n",
        "        \n",
        "        x = Add()([y,x])\n",
        "        x = ReLU()(x)\n",
        "        x = self.cv3(x)\n",
        "        \n",
        "        map = softmax(x,axis=[2,3])\n",
        "\n",
        "\n",
        "        return tf.math.multiply(img,map)\n",
        "\n",
        "\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.applications import *\n",
        "def load_model():   \n",
        "  \n",
        "  K.clear_session() \n",
        "  mod=densenet.DenseNet121(include_top=True, weights='imagenet')\n",
        "  d = mod.get_layer('conv5_block16_concat').output\n",
        "  d = Conv2D(512,1)(d)\n",
        "\n",
        "  a = mod.get_layer('conv3_block12_concat').output\n",
        "  a = Conv2D(256,1)(a)\n",
        "  a = abc(inr=16,mo=256,up=4)(a,d)\n",
        "  a = LayerNormalization()(a)\n",
        "  a = Reshape((28,28,256,))(a)\n",
        "\n",
        "  b = mod.get_layer('conv4_block24_concat').output\n",
        "  b = Conv2D(512,1)(b)\n",
        "  b = abc(inr=16,mo=512,up=2)(b,d)\n",
        "  b = LayerNormalization()(b)\n",
        "  b = Reshape((14,14,512,))(b)\n",
        "    \n",
        "  a = GlobalAveragePooling2D()(a)\n",
        "\n",
        "  b = GlobalAveragePooling2D()(b)\n",
        "\n",
        "  d = GlobalAveragePooling2D()(d)\n",
        "\n",
        "  conc=Concatenate(axis=1)([a,b,d])\n",
        "  conc = Dense(3, activation=\"softmax\")(conc) \n",
        "  \n",
        "  mod=Model(inputs=mod.input,outputs=conc)\n",
        "  return mod\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArRiZ5lS0F9u"
      },
      "source": [
        "mod=load_model()\n",
        "mod.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eq6gnpm4CjDC"
      },
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from keras.activations import softmax\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow import keras\n",
        "from keras.activations import softmax\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow as tf\n",
        "class LayerNormalization(Layer):\n",
        "    def __init__(self, eps=1e-6, **kwargs):\n",
        "        self.eps = eps\n",
        "        super(LayerNormalization, self).__init__(**kwargs)\n",
        "    def build(self, input_shape):\n",
        "        self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:],\n",
        "                                     initializer=Ones(), trainable=True)\n",
        "        self.beta = self.add_weight(name='beta', shape=input_shape[-1:],\n",
        "                                    initializer=Zeros(), trainable=True)\n",
        "        super(LayerNormalization, self).build(input_shape)\n",
        "    def call(self, x):\n",
        "        mean = K.mean(x, axis=-1, keepdims=True)\n",
        "        std = K.std(x, axis=-1, keepdims=True)\n",
        "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "class SpatialGate(keras.layers.Layer):\n",
        "    def __init__(self,**kwargs):\n",
        "        super(SpatialGate, self).__init__(**kwargs)\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super(SpatialGate, self).get_config()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(SpatialGate, self).build(input_shape)\n",
        "        self.cv2 = Conv2D(1,1)\n",
        "    def call(self, img):\n",
        "        \n",
        "        img_avg = K.expand_dims(K.mean(img,-1),-1)\n",
        "        img_max = K.expand_dims(K.max(img,-1),-1)\n",
        "        total = Concatenate(-1)([img_avg,img_max])\n",
        "        x = self.cv2(total)\n",
        "        x = keras.activations.sigmoid(x)\n",
        "        x = K.expand_dims(x,-1)\n",
        "\n",
        "        return tf.math.multiply(img,x)\n",
        "class abc(Layer):\n",
        "    def __init__(self,inr,mo,up,**kwargs):\n",
        "        super(abc, self).__init__(**kwargs)\n",
        "        self.inr=inr\n",
        "        self.mo=mo\n",
        "        self.up=up\n",
        "    def get_config(self):\n",
        "        base_config = super(abc, self).get_config()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(abc, self).build(input_shape)\n",
        "        self.cv1 = Conv2D(self.inr,1)\n",
        "        self.cv2 = Conv2D(self.inr,1)\n",
        "        self.cv3 = Conv2D(1,1)\n",
        "        self.up = UpSampling2D(interpolation='bilinear',size=(self.up,self.up))\n",
        "        self.dns1=Dense(1)\n",
        "    def call(self, img,y):\n",
        "        y = self.cv1(y)\n",
        "        x = self.cv2(img)\n",
        "        y = self.up(y)\n",
        "        x = Concatenate(axis=-1)([y,x])\n",
        "        x = ReLU()(x)\n",
        "        x = self.cv3(x)\n",
        "        \n",
        "        map = softmax(x,axis=[2,3])\n",
        "\n",
        "\n",
        "        return tf.math.multiply(img,map)\n",
        "\n",
        "\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.applications import *\n",
        "\n",
        "class SpatialGate(keras.layers.Layer):\n",
        "    def __init__(self,**kwargs):\n",
        "        super(SpatialGate, self).__init__(**kwargs)\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super(SpatialGate, self).get_config()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(SpatialGate, self).build(input_shape)\n",
        "        self.cv2 = Conv2D(1,1)\n",
        "    def call(self, img):\n",
        "        \n",
        "        img_avg = K.expand_dims(K.mean(img,-1),-1)\n",
        "        img_max = K.expand_dims(K.max(img,-1),-1)\n",
        "        total = Concatenate(-1)([img_avg,img_max])\n",
        "        x = self.cv2(total)\n",
        "        x = keras.activations.sigmoid(x)\n",
        "        return tf.math.multiply(img,x)\n",
        "def load_model():   \n",
        "  \n",
        "  K.clear_session() \n",
        "  mod=densenet.DenseNet121(include_top=True, weights='imagenet')\n",
        "  d = mod.get_layer('conv5_block16_concat').output\n",
        "\n",
        "  a = mod.get_layer('conv3_block12_concat').output\n",
        "  a = abc(inr=16,mo=512,up=4)(a,d)\n",
        "  a = LayerNormalization()(a)\n",
        "  a = Reshape((28,28,512,))(a)\n",
        "\n",
        "  b = mod.get_layer('conv4_block24_concat').output\n",
        "  b = abc(inr=16,mo=1024,up=2)(b,d)\n",
        "  b = LayerNormalization()(b)\n",
        "  b = Reshape((14,14,1024,))(b)\n",
        "    \n",
        "  a = SpatialGate()(a)\n",
        "  a = GlobalAveragePooling2D()(a)\n",
        "\n",
        "  b = SpatialGate()(b)\n",
        "  b = GlobalAveragePooling2D()(b)\n",
        "\n",
        "  d = SpatialGate()(d)\n",
        "  d = GlobalAveragePooling2D()(d)\n",
        "\n",
        "  conc=Concatenate(axis=1)([a,b,d])\n",
        "  conc = Dense(3, activation=\"softmax\")(conc) \n",
        "  \n",
        "  mod=Model(inputs=mod.input,outputs=conc)\n",
        "  return mod\n",
        "\n",
        "\n",
        "\n",
        "import keras\n",
        "import pandas as pd\n",
        "from keras.applications.nasnet import NASNetMobile, preprocess_input\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "def rotate_image(image, angle):\n",
        "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "  return result\n",
        "def Hflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Fliplr(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def Vflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Flipud(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def noise(images):\n",
        "    ls=[]\n",
        "    for i in images:\n",
        "        x = np.random.normal(loc=0, scale=0.05, size=(299,299,3))\n",
        "        ls.append(i+x)\n",
        "    return ls\n",
        "def rotate(images):\n",
        "    ls=[]\n",
        "    for angle in range(-15,20,5):\n",
        "        for image in images:\n",
        "            ls.append(rotate_image(image,angle))\n",
        "    return ls\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "  def __init__(self, images, labels, batch_size=64, image_dimensions = (96 ,96 ,3), shuffle=False, augment=False):\n",
        "    self.labels       = labels              # array of labels\n",
        "    self.images = images        # array of image paths\n",
        "    self.batch_size   = batch_size          # batch size\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.floor(self.labels.shape[0] / self.batch_size))\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    self.indexes = np.arange(self.labels.shape[0])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\t\t# selects indices of data for next batch\n",
        "    indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "    # select data and load images\n",
        "    labels = self.labels.loc[indexes]\n",
        "    img = [self.images[k].astype(np.float32) for k in indexes]\n",
        "    imgH=Hflip(img)\n",
        "    imgV=Vflip(img)\n",
        "    imgR=rotate(img)\n",
        "    images=[]\n",
        "    images.extend(imgH)\n",
        "    images.extend(imgV)\n",
        "    images.extend(imgR)\n",
        "    lbl=labels.copy()\n",
        "    labels=pd.DataFrame()\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    #images = np.array([preprocess_input(img) for img in images])\n",
        "    return np.asarray(images), labels.values\n",
        "\n",
        "\n",
        "best_accuracy_last={}\n",
        "final_accuracy_last={}\n",
        "history_last={}\n",
        "answers_last={}\n",
        "predictions_last={}\n",
        "predictions_last_best={}\n",
        "times_last={}\n",
        "\n",
        "\n",
        "#shuffle samples\n",
        "def unison_shuffled_copies(a, b):\n",
        "    assert len(a) == len(b)\n",
        "    p = np.random.permutation(len(a))\n",
        "    return a[p], b[p]\n",
        "\n",
        "\n",
        "\n",
        "#change targets\n",
        "def change(img):\n",
        "    resized = cv2.resize(img, (224,224), interpolation = cv2.INTER_AREA )\n",
        "    return resized\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#get train and test splits\n",
        "def get_trn_tst(df,tst_fold):\n",
        "  idx=np.asarray(df['fold'])\n",
        "  y=np.asarray(df['label'])\n",
        "  y-=1\n",
        "  img=np.asarray(df['image'])\n",
        "  img1=[]\n",
        "  for i in range(len(img)):\n",
        "        img1.append(change(img[i]))\n",
        "  img1=np.asarray(img1)\n",
        "  del([img])\n",
        "  gc.collect()\n",
        "  trn_y=np.asarray(y[(idx!=tst_fold)])\n",
        "  trn_img=np.asarray(img1[(idx!=tst_fold)])\n",
        "  tst_y=np.asarray(y[(idx==tst_fold)])\n",
        "  tst_img=img1[idx==tst_fold]\n",
        "  trn_img=np.repeat(trn_img.reshape((trn_img.shape[0],224,224,1)),3,axis=3)\n",
        "  tst_img=np.repeat(tst_img.reshape((tst_img.shape[0],224,224,1)),3,axis=3)\n",
        "  return (trn_img.copy(),trn_y.copy()),(tst_img.copy(),tst_y.copy())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cVk9YO8elt-M"
      },
      "source": [
        "\n",
        "best_accuracy_last={}\n",
        "final_accuracy_last={}\n",
        "history_last={}\n",
        "answers_last={}\n",
        "predictions_last={}\n",
        "predictions_last_best={}\n",
        "times_last={}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykeXpxh_lu8L"
      },
      "source": [
        "  def upd(dk,data):\n",
        "    if dk==0:\n",
        "        dk=data\n",
        "    else:\n",
        "        for ky in data.keys():\n",
        "            dk[ky].extend(data[ky])\n",
        "    return dk\n",
        "  index=5\n",
        "  epoch=50\n",
        "  pre_acc=0\n",
        "  best=0\n",
        "  fold='fold_'+str(index)\n",
        "  trn,tst=get_trn_tst(df,index)\n",
        "  history_last[fold]=0\n",
        "\n",
        "\n",
        "\n",
        "  plt.imshow(trn[0][0])\n",
        "  plt.show()\n",
        "  plt.imshow(tst[0][0])\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "  trn_x,trn_y=unison_shuffled_copies(trn[0],trn[1])\n",
        "  tst_x,tst_y=unison_shuffled_copies(tst[0],tst[1])\n",
        "\n",
        "\n",
        "\n",
        "  model=load_model()\n",
        "\n",
        "\n",
        "  \n",
        "  #compiling the model\n",
        "  model.compile(optimizer=Adadelta(6e-5,decay=1e-4), \n",
        "                     loss='categorical_crossentropy', \n",
        "                     metrics=['accuracy'])\n",
        "  train_data = DataGenerator(trn_x,pd.get_dummies(trn_y), batch_size=4, augment=True)\n",
        "  ln=len(trn_y)\n",
        "  # del([trn_x,trn_y,trn,tst])\n",
        "  # gc.collect()\n",
        "  #fitting the model\n",
        "  #timing\n",
        "  start=time.time()\n",
        "  print('training')\n",
        "  hist=model.fit_generator(train_data,epochs=50,steps_per_epoch=ln//4,verbose=0)\n",
        "  history_last[fold]=upd(history_last[fold],hist.history)\n",
        "\n",
        "  end=time.time()\n",
        "  times_last[fold]=end-start\n",
        "\n",
        "  #getting the prediction \n",
        "  pre=model.predict(tst_x)\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "  #select the maximum position\n",
        "  pre=np.argmax(pre,1)\n",
        "  predictions_last[fold]=pre\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "  #getting the accuracy\n",
        "  new_acc=accuracy_score(pre,tst_y)\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  #storing the predictions\n",
        "  final_accuracy_last[fold]=new_acc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #storing the answers\n",
        "  answers_last[fold]=tst_y\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "  #freeing memory\n",
        "  del([tst_x,tst_y])\n",
        "  gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dW_cCm5qClpb",
        "outputId": "7f69c12f-aac3-4e18-f4fd-a48298bdacb9"
      },
      "source": [
        "plt.plot(history_last[fold]['loss'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f1fba748510>]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rm4CwPSqp7ru",
        "outputId": "2c094a75-620a-44b0-c488-3c8ab137a93a"
      },
      "source": [
        "new_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.4463452566096423"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0PuY2ltp9TB"
      },
      "source": [
        "index=str(index)\n",
        "type='gated_spatial_adadelta'\n",
        "model1='final'\n",
        "path='/content/gdrive/My Drive/'\n",
        "np.save(path+\"/best_accuracy_all_fold_\"+index+\"_\"+model1+\"_\"+type+\".npy\",best_accuracy_last)\n",
        "np.save(path+'/final_accuracy_all_fold'+index+\"_\"+model1+\"_\"+type+\".npy\",final_accuracy_last)\n",
        "np.save(path+'/history_all_fold_'+index+\"_\"+model1+\"_\"+type+\".npy\",history_last)\n",
        "np.save(path+'/answers_all_fold_'+index+\"_\"+model1+\"_\"+type+\".npy\",answers_last)\n",
        "np.save(path+'/predictions_all_fold_'+index+\"_\"+model1+\"_\"+type+\".npy\",predictions_last)\n",
        "np.save(path+'/predictions_all_best_fold_'+index+\"_\"+model1+\"_\"+type+\".npy\",predictions_last_best)\n",
        "np.save(path+'/times_all_fold_'+index+\"_\"+model1+\"_\"+type+\".npy\",times_last)\n",
        "model.save_weights(path+type+index+'.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOdQm2sOWzCv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}